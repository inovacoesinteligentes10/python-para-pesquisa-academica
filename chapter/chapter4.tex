% =============================================================================
% CAPÍTULO 4: ANÁLISE ESTATÍSTICA AVANÇADA COM PYTHON
% =============================================================================

\chapter{Análise Estatística Avançada com Python}

A análise estatística é o coração da pesquisa empírica. Este capítulo vai além das estatísticas descritivas básicas, explorando métodos inferenciais robustos, análise de regressão, métodos não-paramétricos e técnicas de reamostragem. Aprenderemos não apenas a executar testes, mas a interpretar resultados criticamente e reportar achados de forma apropriada para publicação.

\section{Fundamentos da Inferência Estatística}

Antes de aplicar testes complexos, é crucial entender os pressupostos subjacentes e quando cada método é apropriado.

\subsection{Verificação de Pressupostos}

A maioria dos testes estatísticos assume normalidade, homogeneidade de variâncias e independência das observações. Violações desses pressupostos podem invalidar conclusões.

\begin{examplebox}
\textbf{Teste de Pressupostos Estatísticos - Configuração Inicial}

\begin{lstlisting}[language=Python]
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.stats.diagnostic import lilliefors

def verificar_pressupostos(dados, grupo_col=None, variavel_dependente=None):
    """
    Verifica pressupostos estatisticos fundamentais
    
    Parametros:
    -----------
    dados : DataFrame
        Dados para analise
    grupo_col : str, optional
        Nome da coluna com grupos (para teste de homogeneidade)
    variavel_dependente : str
        Nome da variavel dependente a ser testada
    """
    
    print("VERIFICACAO DE PRESSUPOSTOS ESTATISTICOS")
    print("="*50)
    
    return dados, grupo_col, variavel_dependente
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Teste de Pressupostos - Normalidade}

\begin{lstlisting}[language=Python]
def testar_normalidade(dados, grupo_col, variavel_dependente):
    """Testa normalidade dos dados"""
    # 1. TESTE DE NORMALIDADE
    print("1. TESTE DE NORMALIDADE")
    print("-" * 25)
    
    if grupo_col:
        # Testar normalidade por grupo
        grupos = dados[grupo_col].unique()
        for grupo in grupos:
            subset = dados[dados[grupo_col] == grupo][variavel_dependente]
            
            # Shapiro-Wilk (melhor para n < 50)
            if len(subset) < 50:
                stat_sw, p_sw = stats.shapiro(subset)
                teste_usado = "Shapiro-Wilk"
                stat_final, p_final = stat_sw, p_sw
            else:
                # Lilliefors (modificacao do KS para normalidade)
                stat_lf, p_lf = lilliefors(subset)
                teste_usado = "Lilliefors"
                stat_final, p_final = stat_lf, p_lf
            
            print(f"   {grupo}: {teste_usado}")
            print(f"     Estatistica: {stat_final:.4f}")
            print(f"     p-valor: {p_final:.4f}")
            print(f"     Normal: {'Sim' if p_final > 0.05 else 'Nao'}")
    else:
        # Teste geral de normalidade
        if len(dados[variavel_dependente]) < 50:
            stat, p = stats.shapiro(dados[variavel_dependente])
            teste = "Shapiro-Wilk"
        else:
            stat, p = lilliefors(dados[variavel_dependente])
            teste = "Lilliefors"
        
        print(f"   {teste}: estatistica = {stat:.4f}, p = {p:.4f}")
        print(f"   Distribuicao normal: {'Sim' if p > 0.05 else 'Nao'}")
        p_final = p
    
    return p_final
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Teste de Pressupostos - Homogeneidade de Variâncias}

\begin{lstlisting}[language=Python]
def testar_homogeneidade(dados, grupo_col, variavel_dependente):
    """Testa homogeneidade de variancias"""
    p_levene = None
    if grupo_col:
        print(f"\n2. HOMOGENEIDADE DE VARIANCIAS")
        print("-" * 30)
        
        # Levene's test (robusto a desvios da normalidade)
        grupos_dados = [dados[dados[grupo_col] == g][variavel_dependente] 
                       for g in dados[grupo_col].unique()]
        
        stat_levene, p_levene = stats.levene(*grupos_dados)
        print(f"   Teste de Levene:")
        print(f"     Estatistica: {stat_levene:.4f}")
        print(f"     p-valor: {p_levene:.4f}")
        print(f"     Variancias homogeneas: {'Sim' if p_levene > 0.05 else 'Nao'}")
        
        # Bartlett (mais sensivel, assume normalidade)
        stat_bartlett, p_bartlett = stats.bartlett(*grupos_dados)
        print(f"   Teste de Bartlett:")
        print(f"     Estatistica: {stat_bartlett:.4f}")
        print(f"     p-valor: {p_bartlett:.4f}")
        print(f"     Variancias homogeneas: {'Sim' if p_bartlett > 0.05 else 'Nao'}")
    
    return p_levene
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Teste de Pressupostos - Diagnósticos Visuais}

\begin{lstlisting}[language=Python]
def diagnosticos_visuais(dados, grupo_col, variavel_dependente):
    """Cria diagnosticos visuais"""
    print(f"\n3. DIAGNOSTICOS VISUAIS")
    print("-" * 20)
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # Q-Q plot para normalidade
    stats.probplot(dados[variavel_dependente], dist="norm", plot=axes[0,0])
    axes[0,0].set_title('Q-Q Plot (Normalidade)')
    axes[0,0].grid(True, alpha=0.3)
    
    # Histograma com curva normal
    axes[0,1].hist(dados[variavel_dependente], bins=20, density=True, alpha=0.7)
    mu, sigma = dados[variavel_dependente].mean(), dados[variavel_dependente].std()
    x = np.linspace(dados[variavel_dependente].min(), dados[variavel_dependente].max(), 100)
    axes[0,1].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal teorica')
    axes[0,1].set_title('Histograma vs Normal')
    axes[0,1].legend()
    
    # Boxplot por grupo (se aplicavel)
    if grupo_col:
        dados.boxplot(column=variavel_dependente, by=grupo_col, ax=axes[1,0])
        axes[1,0].set_title('Boxplot por Grupo')
    else:
        axes[1,0].boxplot(dados[variavel_dependente])
        axes[1,0].set_title('Boxplot Geral')
    
    return axes
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Teste de Pressupostos - Detecção de Outliers e Exemplo}

\begin{lstlisting}[language=Python]
def detectar_outliers(dados, variavel_dependente, axes):
    """Detecta e visualiza outliers"""
    # Teste de outliers
    q1 = dados[variavel_dependente].quantile(0.25)
    q3 = dados[variavel_dependente].quantile(0.75)
    iqr = q3 - q1
    outliers = dados[(dados[variavel_dependente] < q1 - 1.5*iqr) | 
                    (dados[variavel_dependente] > q3 + 1.5*iqr)]
    
    axes[1,1].scatter(range(len(dados)), dados[variavel_dependente], alpha=0.6)
    if len(outliers) > 0:
        outlier_indices = outliers.index
        axes[1,1].scatter(outlier_indices, outliers[variavel_dependente], 
                         color='red', s=50, label=f'{len(outliers)} outliers')
        axes[1,1].legend()
    axes[1,1].set_title('Deteccao de Outliers')
    axes[1,1].set_xlabel('Indice')
    axes[1,1].set_ylabel(variavel_dependente)
    
    plt.tight_layout()
    plt.show()
    
    print(f"   Outliers detectados: {len(outliers)}")
    if len(outliers) > 0:
        print(f"   Indices dos outliers: {list(outliers.index)}")
    
    return outliers

# Exemplo de uso
np.random.seed(42)
dados_exemplo = pd.DataFrame({
    'grupo': np.repeat(['controle', 'experimental'], 50),
    'score': np.concatenate([
        np.random.normal(50, 10, 50),  # controle
        np.random.normal(58, 12, 50)   # experimental
    ])
})

# Adicionar alguns outliers
dados_exemplo.loc[5, 'score'] = 100  # outlier
dados_exemplo.loc[55, 'score'] = 20  # outlier

# Executar verificacao completa
dados, grupo_col, var_dep = verificar_pressupostos(dados_exemplo, 'grupo', 'score')
p_final = testar_normalidade(dados, grupo_col, var_dep)
p_levene = testar_homogeneidade(dados, grupo_col, var_dep)
axes = diagnosticos_visuais(dados, grupo_col, var_dep)
outliers = detectar_outliers(dados, var_dep, axes)
\end{lstlisting}
\end{examplebox}

\section{Testes de Hipóteses Robustos}

Quando os pressupostos dos testes paramétricos são violados, precisamos de alternativas robustas.

\subsection{Comparação de Grupos: Paramétrico vs Não-paramétrico}

\begin{examplebox}
\textbf{Arsenal de Testes - Configuração e Dois Grupos}

\begin{lstlisting}[language=Python]
from scipy.stats import ttest_ind, mannwhitneyu, welch_ttest
from scipy.stats import ttest_rel, wilcoxon
from scipy.stats import f_oneway, kruskal
import pingouin as pg

def bateria_testes_comparacao(dados, grupo_col, variavel_dep, pareado=False):
    """
    Executa bateria completa de testes de comparacao entre grupos
    """
    
    print("BATERIA DE TESTES DE COMPARACAO")
    print("="*40)
    
    grupos = dados[grupo_col].unique()
    
    if len(grupos) == 2:
        # DOIS GRUPOS
        grupo1 = dados[dados[grupo_col] == grupos[0]][variavel_dep]
        grupo2 = dados[dados[grupo_col] == grupos[1]][variavel_dep]
        
        print(f"Comparando: {grupos[0]} vs {grupos[1]}")
        print(f"N1 = {len(grupo1)}, N2 = {len(grupo2)}")
        print(f"M1 = {grupo1.mean():.3f}, M2 = {grupo2.mean():.3f}")
        print(f"DP1 = {grupo1.std():.3f}, DP2 = {grupo2.std():.3f}")
        
        return grupo1, grupo2, grupos
    
    return None, None, grupos
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Arsenal de Testes - Amostras Independentes}

\begin{lstlisting}[language=Python]
def testes_independentes(grupo1, grupo2):
    """Executa testes para amostras independentes"""
    # TESTES PARA AMOSTRAS INDEPENDENTES
    print(f"\nTESTES PARA AMOSTRAS INDEPENDENTES:")
    print("-" * 35)
    
    # 1. Teste t de Student (assume variancias iguais)
    t_stat, p_t = ttest_ind(grupo1, grupo2)
    print(f"1. Teste t de Student:")
    print(f"   t = {t_stat:.3f}, p = {p_t:.3f}")
    
    # 2. Teste t de Welch (nao assume variancias iguais)
    t_welch, p_welch = ttest_ind(grupo1, grupo2, equal_var=False)
    print(f"2. Teste t de Welch:")
    print(f"   t = {t_welch:.3f}, p = {p_welch:.3f}")
    
    # 3. Mann-Whitney U (nao-parametrico)
    u_stat, p_u = mannwhitneyu(grupo1, grupo2, alternative='two-sided')
    print(f"3. Mann-Whitney U:")
    print(f"   U = {u_stat:.3f}, p = {p_u:.3f}")
    
    # 4. Teste robusto (usando pingouin)
    resultado_robusto = pg.ttest(grupo1, grupo2, paired=False)
    print(f"4. Teste robusto (Yuen):")
    print(f"   T = {resultado_robusto['T'].iloc[0]:.3f}")
    print(f"   p = {resultado_robusto['p-val'].iloc[0]:.3f}")
    
    return t_stat
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Arsenal de Testes - Amostras Pareadas}

\begin{lstlisting}[language=Python]
def testes_pareados(grupo1, grupo2):
    """Executa testes para amostras pareadas"""
    # TESTES PARA AMOSTRAS PAREADAS
    print(f"\nTESTES PARA AMOSTRAS PAREADAS:")
    print("-" * 30)
    
    # 1. Teste t pareado
    t_paired, p_paired = ttest_rel(grupo1, grupo2)
    print(f"1. Teste t pareado:")
    print(f"   t = {t_paired:.3f}, p = {p_paired:.3f}")
    
    # 2. Wilcoxon signed-rank
    w_stat, p_w = wilcoxon(grupo1, grupo2)
    print(f"2. Wilcoxon signed-rank:")
    print(f"   W = {w_stat:.3f}, p = {p_w:.3f}")
    
    return t_paired
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Arsenal de Testes - Tamanhos de Efeito}

\begin{lstlisting}[language=Python]
def calcular_tamanhos_efeito(grupo1, grupo2, t_stat):
    """Calcula diferentes tamanhos de efeito"""
    # TAMANHOS DE EFEITO
    print(f"\nTAMANHOS DE EFEITO:")
    print("-" * 18)
    
    # Cohen's d
    pooled_std = np.sqrt(((len(grupo1)-1)*grupo1.var() + 
                         (len(grupo2)-1)*grupo2.var()) / 
                        (len(grupo1)+len(grupo2)-2))
    cohens_d = (grupo1.mean() - grupo2.mean()) / pooled_std
    print(f"Cohen's d = {cohens_d:.3f}")
    
    # Glass's delta (usa DP do grupo controle)
    glass_delta = (grupo1.mean() - grupo2.mean()) / grupo2.std()
    print(f"Glass's delta = {glass_delta:.3f}")
    
    # r de Pearson (a partir do teste t)
    r_pearson = t_stat / np.sqrt(t_stat**2 + (len(grupo1) + len(grupo2) - 2))
    print(f"r de Pearson = {r_pearson:.3f}")
    
    # Interpretacao do tamanho do efeito
    if abs(cohens_d) < 0.2:
        interpretacao = "trivial"
    elif abs(cohens_d) < 0.5:
        interpretacao = "pequeno"
    elif abs(cohens_d) < 0.8:
        interpretacao = "medio"
    else:
        interpretacao = "grande"
    
    print(f"Interpretacao: efeito {interpretacao}")
    
    return cohens_d
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Arsenal de Testes - Múltiplos Grupos (ANOVA)}

\begin{lstlisting}[language=Python]
def testes_multiplos_grupos(dados, grupo_col, variavel_dep):
    """Executa testes para multiplos grupos"""
    grupos = dados[grupo_col].unique()
    print(f"Comparando {len(grupos)} grupos: {list(grupos)}")
    
    # Extrair dados por grupo
    grupos_dados = [dados[dados[grupo_col] == g][variavel_dep] 
                   for g in grupos]
    
    print(f"\nESTATISTICAS DESCRITIVAS:")
    print("-" * 25)
    for i, grupo in enumerate(grupos):
        subset = grupos_dados[i]
        print(f"{grupo}: N={len(subset)}, M={subset.mean():.3f}, DP={subset.std():.3f}")
    
    print(f"\nTESTES OMNIBUS:")
    print("-" * 15)
    
    # 1. ANOVA one-way
    f_stat, p_anova = f_oneway(*grupos_dados)
    print(f"1. ANOVA one-way:")
    print(f"   F = {f_stat:.3f}, p = {p_anova:.3f}")
    
    # 2. Kruskal-Wallis (nao-parametrico)
    h_stat, p_kruskal = kruskal(*grupos_dados)
    print(f"2. Kruskal-Wallis:")
    print(f"   H = {h_stat:.3f}, p = {p_kruskal:.3f}")
    
    # 3. ANOVA robusta (usando pingouin)
    dados_long = dados.copy()
    anova_robusta = pg.welch_anova(data=dados_long, dv=variavel_dep, between=grupo_col)
    print(f"3. ANOVA de Welch (robusta):")
    print(f"   F = {anova_robusta['F'].iloc[0]:.3f}")
    print(f"   p = {anova_robusta['p-unc'].iloc[0]:.3f}")
    
    return grupos_dados, p_anova, dados_long
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Arsenal de Testes - Tamanho de Efeito ANOVA e Post-hoc}
\begin{lstlisting}[language=Python]
def anova_efeito_posthoc(dados, grupo_col, variavel_dep, grupos_dados, p_anova):
   """Calcula tamanho de efeito e testes post-hoc"""
   print(f"\nTAMANHO DE EFEITO:")
   print("-" * 17)
   ss_between = sum(len(g) * (g.mean() - dados[variavel_dep].mean())**2 
                   for g in grupos_dados)
   ss_total = sum((dados[variavel_dep] - dados[variavel_dep].mean())**2)
   eta_squared = ss_between / ss_total
   print(f"Eta-squared = {eta_squared:.3f}")
   if eta_squared < 0.01:
       interpretacao = "trivial"
   elif eta_squared < 0.06:
       interpretacao = "pequeno"
   elif eta_squared < 0.14:
       interpretacao = "medio"
   else:
       interpretacao = "grande"
   print(f"Interpretacao: efeito {interpretacao}")
   if p_anova < 0.05:
       print(f"\nTESTES POST-HOC:")
       print("-" * 15)
       posthoc = pg.pairwise_tukey(data=dados, dv=variavel_dep, between=grupo_col)
       print("Tukey HSD:")
       for _, row in posthoc.iterrows():
           print(f"   {row['A']} vs {row['B']}: p = {row['p-tukey']:.3f}")
np.random.seed(123)
dados_multi = pd.DataFrame({
   'grupo': np.repeat(['controle', 'trat1', 'trat2'], 30),
   'score': np.concatenate([
       np.random.normal(50, 8, 30),
       np.random.normal(55, 9, 30),
       np.random.normal(62, 10, 30)
   ])
})
grupo1, grupo2, grupos = bateria_testes_comparacao(dados_multi, 'grupo', 'score')
if grupo1 is not None:
   t_stat = testes_independentes(grupo1, grupo2)
   cohens_d = calcular_tamanhos_efeito(grupo1, grupo2, t_stat)
else:
   grupos_dados, p_anova, dados_long = testes_multiplos_grupos(dados_multi, 'grupo', 'score')
   anova_efeito_posthoc(dados_multi, 'grupo', 'score', grupos_dados, p_anova)
\end{lstlisting}
\end{examplebox}

\subsection{Análise de Regressão Robusta}

A regressão linear é fundamental, mas precisa de diagnósticos cuidadosos e alternativas robustas.

\begin{examplebox}
\textbf{Regressão Linear - Configuração e Modelo Clássico}

\begin{lstlisting}[language=Python]
import statsmodels.api as sm
from statsmodels.stats.diagnostic import het_breuschpagan, het_white
from statsmodels.stats.stattools import durbin_watson
from sklearn.linear_model import HuberRegressor
from sklearn.metrics import r2_score

def regressao_completa(dados, variavel_dep, preditores):
    """
    Executa regressao linear completa com diagnosticos
    """
    
    print("ANALISE DE REGRESSAO COMPLETA")
    print("="*35)
    
    # Preparar dados
    X = dados[preditores]
    y = dados[variavel_dep]
    X_const = sm.add_constant(X)  # Adicionar intercepto
    
    # 1. REGRESSAO LINEAR CLASSICA
    print("1. REGRESSAO LINEAR CLASSICA")
    print("-" * 28)
    
    modelo = sm.OLS(y, X_const).fit()
    print(modelo.summary())
    
    return modelo, X, y, X_const
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Regressão Linear - Diagnósticos de Resíduos}

\begin{lstlisting}[language=Python]
def diagnosticos_residuos(modelo, X_const):
    """Executa diagnosticos completos dos residuos"""
    # 2. DIAGNOSTICOS DE RESIDUOS
    print(f"\n2. DIAGNOSTICOS DE RESIDUOS")
    print("-" * 27)
    
    residuos = modelo.resid
    valores_preditos = modelo.fittedvalues
    residuos_estudentizados = modelo.get_influence().resid_studentized_external
    
    # Teste de normalidade dos residuos
    stat_norm, p_norm = stats.shapiro(residuos)
    print(f"Normalidade dos residuos (Shapiro): p = {p_norm:.3f}")
    
    # Teste de homocedasticidade
    bp_stat, bp_p, _, _ = het_breuschpagan(residuos, X_const)
    print(f"Homocedasticidade (Breusch-Pagan): p = {bp_p:.3f}")
    
    white_stat, white_p, _, _ = het_white(residuos, X_const)
    print(f"Homocedasticidade (White): p = {white_p:.3f}")
    
    # Teste de independencia (Durbin-Watson)
    dw_stat = durbin_watson(residuos)
    print(f"Independencia (Durbin-Watson): {dw_stat:.3f}")
    print(f"  (Valores entre 1.5-2.5 indicam independencia)")
    
    # Deteccao de outliers
    outliers_residuos = np.where(np.abs(residuos_estudentizados) > 3)[0]
    print(f"Outliers detectados (|resid| > 3): {len(outliers_residuos)}")
    
    return residuos, valores_preditos, residuos_estudentizados, p_norm, bp_p, white_p, dw_stat, outliers_residuos
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Regressão Linear - Visualizações Diagnósticas}

\begin{lstlisting}[language=Python]
def visualizacoes_diagnosticas(residuos, valores_preditos, residuos_estudentizados, dados, preditores):
    """Cria visualizacoes diagnosticas"""
    # 3. VISUALIZACOES DIAGNOSTICAS
    print(f"\n3. DIAGNOSTICOS VISUAIS")
    print("-" * 20)
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # Residuos vs valores preditos
    axes[0,0].scatter(valores_preditos, residuos, alpha=0.7)
    axes[0,0].axhline(y=0, color='r', linestyle='--')
    axes[0,0].set_xlabel('Valores Preditos')
    axes[0,0].set_ylabel('Residuos')
    axes[0,0].set_title('Residuos vs Preditos')
    
    # Q-Q plot dos residuos
    stats.probplot(residuos, dist="norm", plot=axes[0,1])
    axes[0,1].set_title('Q-Q Plot dos Residuos')
    
    # Scale-Location plot
    residuos_padronizados = np.sqrt(np.abs(residuos_estudentizados))
    axes[0,2].scatter(valores_preditos, residuos_padronizados, alpha=0.7)
    axes[0,2].set_xlabel('Valores Preditos')
    axes[0,2].set_ylabel('Residuos Padronizados')
    axes[0,2].set_title('Scale-Location Plot')
    
    # Residuos vs cada preditor
    for i, pred in enumerate(preditores[:3]):  # Maximo 3 preditores
        if i < len(preditores):
            axes[1,i].scatter(dados[pred], residuos, alpha=0.7)
            axes[1,i].axhline(y=0, color='r', linestyle='--')
            axes[1,i].set_xlabel(pred)
            axes[1,i].set_ylabel('Residuos')
            axes[1,i].set_title(f'Residuos vs {pred}')
    
    plt.tight_layout()
    plt.show()
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Regressão Linear - Regressão Robusta e Interpretação}

\begin{lstlisting}[language=Python]
def regressao_robusta_interpretacao(modelo, X, y, preditores, p_norm, bp_p, white_p, dw_stat, outliers_residuos):
    """Executa regressao robusta e interpretacao final"""
    print(f"\n4. REGRESSAO ROBUSTA (Huber)")
    print("-" * 27)
    huber = HuberRegressor(epsilon=1.35, max_iter=1000)
    huber.fit(X, y)
    y_pred_huber = huber.predict(X)
    r2_huber = r2_score(y, y_pred_huber)
    print(f"R2 da regressao robusta: {r2_huber:.3f}")
    print(f"R2 da regressao classica: {modelo.rsquared:.3f}")
    print(f"\nCoeficientes:")
    print(f"{'Variavel':<15} {'OLS':<12} {'Huber':<12} {'Diferenca'}")
    print("-" * 45)
    print(f"{'Intercepto':<15} {modelo.params[0]:<12.3f} {huber.intercept_:<12.3f} {abs(modelo.params[0] - huber.intercept_):<12.3f}")
    for i, pred in enumerate(preditores):
        diff = abs(modelo.params[i+1] - huber.coef_[i])
        print(f"{pred:<15} {modelo.params[i+1]:<12.3f} {huber.coef_[i]:<12.3f} {diff:<12.3f}")
    print(f"\n5. INTERPRETACAO E RECOMENDACOES")
    print("-" * 32)
    pressupostos_ok = True
    if p_norm < 0.05:
        print("AVISO: Residuos nao seguem distribuicao normal")
        pressupostos_ok = False
    if bp_p < 0.05 or white_p < 0.05:
        print("AVISO: Heterocedasticidade detectada")
        pressupostos_ok = False
    if dw_stat < 1.5 or dw_stat > 2.5:
        print("AVISO: Possivel autocorrelacao nos residuos")
        pressupostos_ok = False
    if len(outliers_residuos) > 0:
        print(f"AVISO: {len(outliers_residuos)} outliers detectados")
        pressupostos_ok = False
    if pressupostos_ok:
        print("- Todos os pressupostos da regressao satisfeitos")
        print("- Resultados da regressao OLS sao confiaveis")
    else:
        print("\nRECOMENDACOES:")
        print("- Considere transformacao de variaveis")
        print("- Use regressao robusta (Huber mostrada acima)")
        print("- Investigue e possivelmente remova outliers")
        print("- Considere modelos nao-lineares")
    return huber, pressupostos_ok
np.random.seed(42)
n = 100
\end{lstlisting}
\end{examplebox}


\begin{examplebox}
\textbf{Regressão Linear - Regressão Robusta e Interpretação - Continuação}
\begin{lstlisting}[language=Python]
dados_reg = pd.DataFrame({
    'idade': np.random.randint(20, 60, n),
    'educacao': np.random.randint(8, 20, n),
    'experiencia': np.random.randint(0, 30, n)
})
dados_reg['salario'] = (dados_reg['idade'] * 500 + 
                       dados_reg['educacao'] * 2000 + 
                       dados_reg['experiencia'] * 800 + 
                       np.random.normal(0, 5000, n))
dados_reg.loc[5, 'salario'] = 150000  # outlier alto
dados_reg.loc[25, 'salario'] = 10000   # outlier baixo
modelo, X, y, X_const = regressao_completa(dados_reg, 'salario', ['idade', 'educacao', 'experiencia'])
residuos, valores_preditos, residuos_estudentizados, p_norm, bp_p, white_p, dw_stat, outliers_residuos = diagnosticos_residuos(modelo, X_const)
visualizacoes_diagnosticas(residuos, valores_preditos, residuos_estudentizados, dados_reg, ['idade', 'educacao', 'experiencia'])
huber, pressupostos_ok = regressao_robusta_interpretacao(modelo, X, y, ['idade', 'educacao', 'experiencia'], p_norm, bp_p, white_p, dw_stat, outliers_residuos)
\end{lstlisting}
\end{examplebox}

\section{Métodos de Reamostragem}

Quando os métodos tradicionais falham ou quando queremos estimativas mais robustas, métodos de reamostragem oferecem alternativas poderosas.

\subsection{Bootstrap: Estimando Distribuições}

\begin{researchbox}
\textbf{Bootstrap - Análise Básica}

\begin{lstlisting}[language=Python]
from sklearn.utils import resample

def bootstrap_analise(dados, estatistica_func, n_bootstrap=10000, alpha=0.05):
    """
    Realiza analise bootstrap para qualquer estatistica
    
    Parametros:
    -----------
    dados : array-like
        Dados originais
    estatistica_func : function
        Funcao que calcula a estatistica de interesse
    n_bootstrap : int
        Numero de amostras bootstrap
    alpha : float
        Nivel de significancia para IC
    """
    
    print("ANALISE BOOTSTRAP")
    print("="*20)
    
    # Estatistica original
    stat_original = estatistica_func(dados)
    print(f"Estatistica original: {stat_original:.4f}")
    
    # Gerar amostras bootstrap
    bootstrap_stats = []
    
    for i in range(n_bootstrap):
        # Reamostragem com reposicao
        amostra_boot = resample(dados, n_samples=len(dados), replace=True)
        stat_boot = estatistica_func(amostra_boot)
        bootstrap_stats.append(stat_boot)
    
    bootstrap_stats = np.array(bootstrap_stats)
    
    return stat_original, bootstrap_stats
\end{lstlisting}
\end{researchbox}

\begin{researchbox}
\textbf{Bootstrap - Intervalos de Confiança e Visualização}

\begin{lstlisting}[language=Python]
def bootstrap_intervalos_viz(stat_original, bootstrap_stats, alpha=0.05):
    """Calcula intervalos de confianca e cria visualizacoes"""
    # Calcular intervalos de confianca
    ci_lower = np.percentile(bootstrap_stats, (alpha/2) * 100)
    ci_upper = np.percentile(bootstrap_stats, (1 - alpha/2) * 100)
    
    # Bias e erro padrao
    bias = np.mean(bootstrap_stats) - stat_original
    erro_padrao = np.std(bootstrap_stats)
    
    print(f"Bias bootstrap: {bias:.4f}")
    print(f"Erro padrao bootstrap: {erro_padrao:.4f}")
    print(f"IC {(1-alpha)*100:.0f}%: [{ci_lower:.4f}, {ci_upper:.4f}]")
    
    # Visualizacao
    plt.figure(figsize=(12, 4))
    
    # Histograma das estatisticas bootstrap
    plt.subplot(1, 2, 1)
    plt.hist(bootstrap_stats, bins=50, alpha=0.7, density=True)
    plt.axvline(stat_original, color='red', linestyle='--', 
                label=f'Original: {stat_original:.3f}')
    plt.axvline(ci_lower, color='green', linestyle='--', alpha=0.7)
    plt.axvline(ci_upper, color='green', linestyle='--', alpha=0.7, 
                label=f'IC {(1-alpha)*100:.0f}%')
    plt.xlabel('Valor da Estatistica')
    plt.ylabel('Densidade')
    plt.title('Distribuicao Bootstrap')
    plt.legend()
    
    # Q-Q plot para verificar normalidade da distribuicao bootstrap
    plt.subplot(1, 2, 2)
    stats.probplot(bootstrap_stats, dist="norm", plot=plt)
    plt.title('Q-Q Plot: Distribuicao Bootstrap')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    return bias, erro_padrao, ci_lower, ci_upper
\end{lstlisting}
\end{researchbox}

\begin{researchbox}
\textbf{Bootstrap - Exemplos de Aplicação}

\begin{lstlisting}[language=Python]
# Exemplos de uso do bootstrap
np.random.seed(123)
dados_assimetricos = np.random.exponential(2, 100)  # Dados nao-normais

print("EXEMPLO 1: MEDIA DE DISTRIBUICAO ASSIMETRICA")
print("=" * 45)
stat_orig, boot_stats = bootstrap_analise(dados_assimetricos, np.mean)
bias, erro_padrao, ci_lower, ci_upper = bootstrap_intervalos_viz(stat_orig, boot_stats)

print("\nEXEMPLO 2: CORRELACAO")
print("=" * 20)
# Dados bivariados
x = np.random.normal(0, 1, 50)
y = 0.7*x + np.random.normal(0, 0.5, 50)
dados_correlacao = np.column_stack([x, y])

def correlacao_func(dados):
    return np.corrcoef(dados[:, 0], dados[:, 1])[0, 1]

stat_orig_corr, boot_stats_corr = bootstrap_analise(dados_correlacao, correlacao_func)
bias_corr, erro_padrao_corr, ci_lower_corr, ci_upper_corr = bootstrap_intervalos_viz(stat_orig_corr, boot_stats_corr)
\end{lstlisting}
\end{researchbox}

\begin{researchbox}
\textbf{Bootstrap - Diferença entre Grupos}

\begin{lstlisting}[language=Python]
print("\nEXEMPLO 3: DIFERENCA ENTRE MEDIAS")
print("=" * 30)
grupo1 = np.random.normal(50, 10, 30)
grupo2 = np.random.normal(55, 12, 25)

# Bootstrap para diferenca entre grupos (versao simplificada)
def bootstrap_grupos(grupo1, grupo2, n_bootstrap=10000):
    """Bootstrap especifico para diferenca entre grupos"""
    diffs = []
    for _ in range(n_bootstrap):
        boot_g1 = resample(grupo1)
        boot_g2 = resample(grupo2)
        diff = np.mean(boot_g1) - np.mean(boot_g2)
        diffs.append(diff)
    return np.array(diffs)

diffs_boot = bootstrap_grupos(grupo1, grupo2)
diff_original = np.mean(grupo1) - np.mean(grupo2)

print(f"Diferenca original: {diff_original:.3f}")
print(f"IC 95% bootstrap: [{np.percentile(diffs_boot, 2.5):.3f}, {np.percentile(diffs_boot, 97.5):.3f}]")

# Visualizar distribuicao das diferencas
plt.figure(figsize=(8, 5))
plt.hist(diffs_boot, bins=50, alpha=0.7, density=True)
plt.axvline(diff_original, color='red', linestyle='--', label=f'Diferenca observada: {diff_original:.3f}')
plt.axvline(np.percentile(diffs_boot, 2.5), color='green', linestyle='--', alpha=0.7)
plt.axvline(np.percentile(diffs_boot, 97.5), color='green', linestyle='--', alpha=0.7, label='IC 95%')
plt.xlabel('Diferenca entre Medias')
plt.ylabel('Densidade')
plt.title('Bootstrap: Diferenca entre Grupos')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
\end{lstlisting}
\end{researchbox}

\subsection{Testes de Permutação}

Quando não podemos assumir distribuições específicas, testes de permutação oferecem uma alternativa exata.

\begin{examplebox}
\textbf{Testes de Permutação - Função Principal}

\begin{lstlisting}[language=Python]
def teste_permutacao(grupo1, grupo2, estatistica_func=None, n_perm=10000):
    """
    Realiza teste de permutacao para comparar dois grupos
    
    Parametros:
    -----------
    grupo1, grupo2 : array-like
        Dados dos dois grupos
    estatistica_func : function
        Funcao para calcular estatistica (default: diferenca de medias)
    n_perm : int
        Numero de permutacoes
    """
    
    if estatistica_func is None:
        estatistica_func = lambda g1, g2: np.mean(g1) - np.mean(g2)
    
    print("TESTE DE PERMUTACAO")
    print("=" * 20)
    
    # Estatistica observada
    stat_observada = estatistica_func(grupo1, grupo2)
    print(f"Estatistica observada: {stat_observada:.4f}")
    
    # Combinar todos os dados
    dados_combinados = np.concatenate([grupo1, grupo2])
    n1, n2 = len(grupo1), len(grupo2)
    
    return stat_observada, dados_combinados, n1, n2
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Testes de Permutação - Distribuição Nula e P-valor}

\begin{lstlisting}[language=Python]
def permutacao_distribuicao_nula(stat_observada, dados_combinados, n1, n2, estatistica_func, n_perm=10000):
    """Gera distribuicao nula e calcula p-valor"""
    # Gerar distribuicao nula por permutacao
    stats_permutacao = []
    
    for i in range(n_perm):
        # Permutacao aleatoria
        dados_permutados = np.random.permutation(dados_combinados)
        
        # Dividir novamente nos grupos originais
        perm_g1 = dados_permutados[:n1]
        perm_g2 = dados_permutados[n1:]
        
        # Calcular estatistica para esta permutacao
        stat_perm = estatistica_func(perm_g1, perm_g2)
        stats_permutacao.append(stat_perm)
    
    stats_permutacao = np.array(stats_permutacao)
    
    # Calcular p-valor
    # Para teste bilateral
    p_valor = np.mean(np.abs(stats_permutacao) >= np.abs(stat_observada))
    
    print(f"P-valor (bilateral): {p_valor:.4f}")
    
    return stats_permutacao, p_valor
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Testes de Permutação - Visualização}

\begin{lstlisting}[language=Python]
def permutacao_visualizacao(stat_observada, stats_permutacao):
    """Cria visualizacao do teste de permutacao"""
    # Visualizacao
    plt.figure(figsize=(10, 6))
    
    plt.hist(stats_permutacao, bins=50, alpha=0.7, density=True, 
             label='Distribuicao nula')
    plt.axvline(stat_observada, color='red', linestyle='--', linewidth=2,
                label=f'Estatistica observada: {stat_observada:.3f}')
    plt.axvline(-stat_observada, color='red', linestyle='--', linewidth=2, alpha=0.7)
    
    # Marcar regiao critica
    critico_superior = np.percentile(stats_permutacao, 97.5)
    critico_inferior = np.percentile(stats_permutacao, 2.5)
    
    x_fill = np.linspace(critico_superior, max(stats_permutacao), 100)
    plt.fill_between(x_fill, 0, stats.norm.pdf(x_fill, np.mean(stats_permutacao), 
                                              np.std(stats_permutacao)), 
                     alpha=0.3, color='red', label='Regiao critica (alpha=0.05)')
    
    x_fill2 = np.linspace(min(stats_permutacao), critico_inferior, 100)
    plt.fill_between(x_fill2, 0, stats.norm.pdf(x_fill2, np.mean(stats_permutacao), 
                                               np.std(stats_permutacao)), 
                     alpha=0.3, color='red')
    
    plt.xlabel('Estatistica de Teste')
    plt.ylabel('Densidade')
    plt.title('Teste de Permutacao: Distribuicao Nula')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Testes de Permutação - Visualização - Continuação}

\begin{lstlisting}[language=Python]
# Exemplo de uso
np.random.seed(42)
controle = np.random.normal(50, 10, 25)
tratamento = np.random.normal(58, 12, 30)

print("EXEMPLO: COMPARACAO DE MEDIAS")
stat_obs, dados_comb, n1, n2 = teste_permutacao(controle, tratamento)
def diff_medias_func(g1, g2): return np.mean(g1) - np.mean(g2)
stats_perm, p_val = permutacao_distribuicao_nula(stat_obs, dados_comb, n1, n2, diff_medias_func)
permutacao_visualizacao(stat_obs, stats_perm)

# Exemplo com estatistica customizada (diferenca de medianas)
def diff_medianas(g1, g2):
    return np.median(g1) - np.median(g2)

print("\nEXEMPLO: COMPARACAO DE MEDIANAS")
stat_obs_med, dados_comb_med, n1_med, n2_med = teste_permutacao(controle, tratamento)
stats_perm_med, p_val_med = permutacao_distribuicao_nula(stat_obs_med, dados_comb_med, n1_med, n2_med, diff_medianas)
permutacao_visualizacao(stat_obs_med, stats_perm_med)
\end{lstlisting}
\end{examplebox}

\section{Análise Multivariada}

Pesquisas frequentemente envolvem múltiplas variáveis interrelacionadas, exigindo métodos multivariados.

\subsection{Análise de Componentes Principais (PCA)}

\begin{researchbox}
\textbf{PCA - Configuração e Análise Inicial}

\begin{lstlisting}[language=Python]
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_blobs

def analise_pca_completa(dados, n_componentes=None, padronizar=True):
    """
    Realiza PCA completa com interpretacao e visualizacao
    
    Parametros:
    -----------
    dados : DataFrame
        Dados numericos para PCA
    n_componentes : int, optional
        Numero de componentes a reter
    padronizar : bool
        Se deve padronizar as variaveis
    """
    
    print("ANALISE DE COMPONENTES PRINCIPAIS")
    print("=" * 35)
    
    # Preparar dados
    if padronizar:
        scaler = StandardScaler()
        dados_scaled = scaler.fit_transform(dados)
        print("Dados padronizados (media=0, dp=1)")
    else:
        dados_scaled = dados.values
        print("Dados originais (sem padronizacao)")
    
    # PCA inicial para ver todas as componentes
    pca_completo = PCA()
    pca_completo.fit(dados_scaled)
    
    # Variancia explicada
    var_explicada = pca_completo.explained_variance_ratio_
    var_cumulativa = np.cumsum(var_explicada)
    
    print(f"\nVariancia explicada por componente:")
    for i, var in enumerate(var_explicada[:min(10, len(var_explicada))]):
        print(f"  PC{i+1}: {var:.3f} ({var*100:.1f}%)")
    
    return dados_scaled, pca_completo, var_explicada, var_cumulativa
\end{lstlisting}
\end{researchbox}

\begin{researchbox}
\textbf{PCA - Seleção de Componentes e Análise Final}

\begin{lstlisting}[language=Python]
def pca_selecao_componentes(dados, dados_scaled, var_explicada, var_cumulativa, n_componentes=None):
    """Seleciona numero ideal de componentes e executa PCA final"""
    # Determinar numero ideal de componentes
    if n_componentes is None:
        # Criterio de Kaiser (eigenvalues > 1)
        eigenvalues = pca_completo.explained_variance_
        n_kaiser = np.sum(eigenvalues > 1)
        
        # Criterio de 95% da variancia
        n_95 = np.argmax(var_cumulativa >= 0.95) + 1
        
        print(f"\nCriterios para selecao de componentes:")
        print(f"  Kaiser (eigenvalue > 1): {n_kaiser} componentes")
        print(f"  95% da variancia: {n_95} componentes")
        
        n_componentes = min(n_kaiser, n_95)
        print(f"  Recomendado: {n_componentes} componentes")
    
    # PCA final com numero escolhido
    pca = PCA(n_components=n_componentes)
    dados_pca = pca.fit_transform(dados_scaled)
    
    print(f"\nPCA final com {n_componentes} componentes:")
    print(f"Variancia total explicada: {pca.explained_variance_ratio_.sum():.3f} ({pca.explained_variance_ratio_.sum()*100:.1f}%)")
    
    # Loadings (pesos das variaveis originais)
    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)
    loadings_df = pd.DataFrame(loadings, 
                              index=dados.columns, 
                              columns=[f'PC{i+1}' for i in range(n_componentes)])
    
    print(f"\nLoadings das variaveis:")
    print(loadings_df.round(3))
    
    return pca, dados_pca, loadings_df, n_componentes
\end{lstlisting}
\end{researchbox}

\begin{researchbox}
\textbf{PCA - Interpretação dos Componentes}

\begin{lstlisting}[language=Python]
def pca_interpretacao(pca, loadings_df, n_componentes):
    """Interpreta os componentes principais"""
    # Interpretacao dos componentes
    print(f"\nINTERPRETACAO DOS COMPONENTES:")
    for i in range(n_componentes):
        print(f"\nPC{i+1} (variancia explicada: {pca.explained_variance_ratio_[i]:.3f}):")
        
        # Variaveis com maior peso (positivo e negativo)
        pc_loadings = loadings_df[f'PC{i+1}'].abs().sort_values(ascending=False)
        print(f"  Variaveis mais importantes:")
        
        for var in pc_loadings.head(3).index:
            loading = loadings_df.loc[var, f'PC{i+1}']
            print(f"    {var}: {loading:.3f}")
\end{lstlisting}
\end{researchbox}

\begin{researchbox}
\textbf{PCA - Visualizações}

\begin{lstlisting}[language=Python]
def pca_visualizacoes(dados, pca, dados_pca, loadings_df, var_explicada, var_cumulativa, n_componentes):
    """Cria visualizacoes do PCA"""
    # Visualizacoes
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # 1. Scree plot
    axes[0,0].plot(range(1, len(var_explicada[:10])+1), var_explicada[:10], 'bo-')
    axes[0,0].axhline(y=1/len(dados.columns), color='r', linestyle='--', 
                     label='Media da variancia')
    axes[0,0].set_xlabel('Componente')
    axes[0,0].set_ylabel('Variancia Explicada')
    axes[0,0].set_title('Scree Plot')
    axes[0,0].legend()
    axes[0,0].grid(True, alpha=0.3)
    
    # 2. Variancia cumulativa
    axes[0,1].plot(range(1, len(var_cumulativa[:10])+1), var_cumulativa[:10], 'go-')
    axes[0,1].axhline(y=0.95, color='r', linestyle='--', label='95%')
    axes[0,1].set_xlabel('Numero de Componentes')
    axes[0,1].set_ylabel('Variancia Cumulativa')
    axes[0,1].set_title('Variancia Cumulativa Explicada')
    axes[0,1].legend()
    axes[0,1].grid(True, alpha=0.3)
    
    return axes
\end{lstlisting}
\end{researchbox}

\begin{researchbox}
\textbf{PCA - Biplot e Heatmap}

\begin{lstlisting}[language=Python]
def pca_biplot_heatmap(dados, dados_pca, loadings_df, pca, n_componentes, axes):
    """Cria biplot e heatmap"""
    # 3. Biplot (se temos pelo menos 2 componentes)
    if n_componentes >= 2:
        loadings = loadings_df.values
        # Scatter dos scores
        axes[1,0].scatter(dados_pca[:, 0], dados_pca[:, 1], alpha=0.7)
        
        # Adicionar vetores das variaveis
        for i, var in enumerate(dados.columns):
            axes[1,0].arrow(0, 0, loadings[i, 0]*3, loadings[i, 1]*3, 
                           head_width=0.1, head_length=0.1, fc='red', ec='red')
            axes[1,0].text(loadings[i, 0]*3.2, loadings[i, 1]*3.2, var, 
                          fontsize=9, ha='center')
        
        axes[1,0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')
        axes[1,0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')
        axes[1,0].set_title('Biplot PC1 vs PC2')
        axes[1,0].grid(True, alpha=0.3)
    
    # 4. Heatmap dos loadings
    sns.heatmap(loadings_df.T, annot=True, cmap='RdBu_r', center=0, 
                ax=axes[1,1], fmt='.2f')
    axes[1,1].set_title('Heatmap dos Loadings')
    
    plt.tight_layout()
    plt.show()

# Dados de exemplo: simulando questionario psicologico
np.random.seed(42)
n_participantes = 200

# Simular fatores latentes
fator_ansiedade = np.random.normal(0, 1, n_participantes)
fator_depressao = np.random.normal(0, 1, n_participantes)
fator_autoestima = np.random.normal(0, 1, n_participantes)
\end{lstlisting}
\end{researchbox}

\begin{researchbox}
\textbf{PCA - Biplot e Heatmap - Continuação}
\begin{lstlisting}[language=Python]
# Criar variaveis observadas com ruido
dados_psico = pd.DataFrame({
    'ansiedade_1': fator_ansiedade + np.random.normal(0, 0.5, n_participantes),
    'ansiedade_2': fator_ansiedade + np.random.normal(0, 0.5, n_participantes),
    'ansiedade_3': fator_ansiedade + np.random.normal(0, 0.5, n_participantes),
    'depressao_1': fator_depressao + np.random.normal(0, 0.5, n_participantes),
    'depressao_2': fator_depressao + np.random.normal(0, 0.5, n_participantes),
    'depressao_3': fator_depressao + np.random.normal(0, 0.5, n_participantes),
    'autoestima_1': -fator_autoestima + np.random.normal(0, 0.5, n_participantes),
    'autoestima_2': -fator_autoestima + np.random.normal(0, 0.5, n_participantes),
})

# Executar PCA completo
dados_scaled, pca_completo, var_explicada, var_cumulativa = analise_pca_completa(dados_psico)
pca, dados_pca, loadings_df, n_componentes = pca_selecao_componentes(dados_psico, dados_scaled, var_explicada, var_cumulativa)
pca_interpretacao(pca, loadings_df, n_componentes)
axes = pca_visualizacoes(dados_psico, pca, dados_pca, loadings_df, var_explicada, var_cumulativa, n_componentes)
pca_biplot_heatmap(dados_psico, dados_pca, loadings_df, pca, n_componentes, axes)
\end{lstlisting}
\end{researchbox}

\section{Controle de Erro Tipo I em Múltiplas Comparações}

Quando realizamos múltiplos testes, a probabilidade de erro Tipo I inflaciona dramaticamente.

\begin{warningbox}
\textbf{O Problema das Múltiplas Comparações:}

Se realizarmos 20 testes independentes com alpha = 0.05, a probabilidade de pelo menos um falso positivo é:

$P(\text{pelo menos 1 falso positivo}) = 1 - (0.95)^{20} \approx 0.64$

Ou seja, 64\% de chance de erro Tipo I!
\end{warningbox}

\begin{examplebox}
\textbf{Correções para Múltiplas Comparações - Configuração}

\begin{lstlisting}[language=Python]
from statsmodels.stats.multitest import multipletests

def correcao_multiplas_comparacoes(p_valores, metodos=['bonferroni', 'holm', 'fdr_bh']):
    """
    Aplica diferentes metodos de correcao para multiplas comparacoes
    
    Parametros:
    -----------
    p_valores : array-like
        Lista de p-valores nao corrigidos
    metodos : list
        Metodos de correcao a aplicar
    """
    
    print("CORRECAO PARA MULTIPLAS COMPARACOES")
    print("=" * 40)
    
    p_valores = np.array(p_valores)
    n_testes = len(p_valores)
    
    print(f"Numero de testes: {n_testes}")
    print(f"P-valores originais: {p_valores}")
    print(f"Significativos sem correcao (alpha=0.05): {np.sum(p_valores < 0.05)}")
    
    # Calcular inflacao do erro Tipo I
    erro_familywise = 1 - (1 - 0.05)**n_testes
    print(f"Erro Tipo I familywise sem correcao: {erro_familywise:.3f}")
    
    print(f"\nCORRECOES APLICADAS:")
    print("-" * 20)
    
    return p_valores, n_testes
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Correções para Múltiplas Comparações - Aplicação dos Métodos}

\begin{lstlisting}[language=Python]
def aplicar_correcoes(p_valores, metodos):
    """Aplica diferentes metodos de correcao"""
    resultados = {}
    
    for metodo in metodos:
        reject, p_corrigidos, alpha_sidak, alpha_bonf = multipletests(
            p_valores, alpha=0.05, method=metodo, returnsorted=False)
        
        n_significativos = np.sum(reject)
        
        print(f"\n{metodo.upper()}:")
        print(f"  P-valores corrigidos: {p_corrigidos.round(4)}")
        print(f"  Significativos apos correcao: {n_significativos}")
        print(f"  Indices significativos: {np.where(reject)[0]}")
        
        resultados[metodo] = {
            'p_corrigidos': p_corrigidos,
            'significativos': reject,
            'n_significativos': n_significativos
        }
    
    return resultados
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Correções para Múltiplas Comparações - Visualizações}

\begin{lstlisting}[language=Python]
def visualizar_correcoes(p_valores, resultados, metodos):
    """Cria visualizacoes das correcoes"""
    # Visualizacao
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
    
    # Comparacao dos p-valores
    x = np.arange(len(p_valores))
    largura = 0.2
    
    ax1.bar(x - largura, p_valores, largura, label='Original', alpha=0.8)
    
    for i, metodo in enumerate(metodos):
        offset = largura * (i - len(metodos)/2 + 1)
        ax1.bar(x + offset, resultados[metodo]['p_corrigidos'], largura, 
               label=metodo.replace('_', ' ').title(), alpha=0.8)
    
    ax1.axhline(y=0.05, color='red', linestyle='--', alpha=0.7, label='alpha = 0.05')
    ax1.set_xlabel('Indice do Teste')
    ax1.set_ylabel('P-valor')
    ax1.set_title('Comparacao de P-valores')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Numero de descobertas significativas
    metodos_plot = ['Original'] + metodos
    n_sig_plot = [np.sum(p_valores < 0.05)] + [resultados[m]['n_significativos'] for m in metodos]
    
    cores = ['red'] + ['blue', 'green', 'orange'][:len(metodos)]
    bars = ax2.bar(metodos_plot, n_sig_plot, color=cores, alpha=0.7)
    
    # Adicionar valores nas barras
    for bar in bars:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{int(height)}', ha='center', va='bottom')
    
    ax2.set_xlabel('Metodo de Correcao')
    ax2.set_ylabel('Numero de Testes Significativos')
    ax2.set_title('Impacto das Correcoes')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    return resultados
\end{lstlisting}
\end{examplebox}

\begin{examplebox}
\textbf{Correções para Múltiplas Comparações - Exemplo Completo}

\begin{lstlisting}[language=Python]
# Simular exemplo com multiplas comparacoes
np.random.seed(123)

# Simular 15 testes: 3 com efeito real, 12 sem efeito
p_valores_exemplo = []

# 3 testes com efeito real (p-valores baixos)
for _ in range(3):
    # Simular dados com diferenca real
    grupo1 = np.random.normal(50, 10, 30)
    grupo2 = np.random.normal(58, 10, 30)  # Diferenca real
    _, p = stats.ttest_ind(grupo1, grupo2)
    p_valores_exemplo.append(p)

# 12 testes sem efeito (apenas ruido)
for _ in range(12):
    # Simular dados sem diferenca
    grupo1 = np.random.normal(50, 10, 30)
    grupo2 = np.random.normal(50, 10, 30)  # Sem diferenca
    _, p = stats.ttest_ind(grupo1, grupo2)
    p_valores_exemplo.append(p)

print("EXEMPLO: 15 TESTES (3 com efeito real, 12 sem efeito)")
print("=" * 55)

# Executar correcoes
p_valores, n_testes = correcao_multiplas_comparacoes(p_valores_exemplo)
resultados = aplicar_correcoes(p_valores, ['bonferroni', 'holm', 'fdr_bh'])
resultado_final = visualizar_correcoes(p_valores, resultados, ['bonferroni', 'holm', 'fdr_bh'])
\end{lstlisting}
\end{examplebox}

\section{Exercícios Práticos Avançados}

\begin{examplebox}
\textbf{Exercício 1: Meta-Análise Simples}

Implemente uma função que combine resultados de múltiplos estudos usando meta-análise de efeitos fixos e aleatórios. Use dados simulados de 8 estudos com tamanhos de amostra diferentes.

\textbf{Exercício 2: Análise de Mediação}

Crie uma análise completa de mediação usando bootstrap para testar se uma variável medeia a relação entre X e Y. Inclua teste de Sobel e intervalos de confiança bootstrap.

\textbf{Exercício 3: Análise de Regressão Logística}

Desenvolva uma função que execute regressão logística completa com diagnósticos, incluindo teste de Hosmer-Lemeshow, curva ROC, e validação cruzada.

\textbf{Exercício 4: Análise de Sobrevivência Básica}

Implemente análise de Kaplan-Meier com teste log-rank para comparar curvas de sobrevivência entre grupos.
\end{examplebox}

Este capítulo forneceu ferramentas estatísticas avançadas essenciais para pesquisa rigorosa. No próximo capítulo, exploraremos machine learning aplicado à pesquisa acadêmica, incluindo classificação, regressão e métodos de aprendizado não supervisionado para descoberta de padrões em dados complexos.