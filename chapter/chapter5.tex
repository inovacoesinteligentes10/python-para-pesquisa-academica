% =============================================================================
% CAPÍTULO 5: METODOLOGIA DE PESQUISA COM PYTHON
% =============================================================================

\chapter{Metodologia de Pesquisa com Python}

\lettrine{A}{pesquisa científica moderna} exige não apenas rigor metodológico, mas também eficiência computacional e reprodutibilidade. Python oferece um framework completo para estruturar projetos de pesquisa de forma organizada, desde o planejamento inicial até a publicação dos resultados. Este capítulo apresenta metodologias e melhores práticas para conduzir pesquisa acadêmica utilizando Python como ferramenta central.

\section{Planejamento de Projetos de Pesquisa}

Um projeto de pesquisa bem estruturado em Python começa com planejamento cuidadoso. A organização inicial determina a facilidade de manutenção, colaboração e reprodução dos resultados ao longo de todo o ciclo de vida da pesquisa.

\subsection{Estrutura de Diretórios para Projetos de Pesquisa}
\begin{pythonbox}
\begin{lstlisting}[language=bash]
projeto_pesquisa/
 README.md                 # Descrição do projeto
 requirements.txt          # Dependências Python
 environment.yml          # Ambiente conda (alternativa)
 .gitignore              # Arquivos ignorados pelo Git
 setup.py                # Configuração do pacote
 data/                   # Dados do projeto
    raw/               # Dados brutos (nunca modificar)
    interim/           # Dados em processamento
    processed/         # Dados finais para análise
    external/          # Dados de fontes externas
 notebooks/             # Jupyter notebooks
    exploratory/       # Análise exploratória
    reports/           # Notebooks finais
    sandbox/           # Testes e experimentos
 src/                   # Código fonte
    __init__.py
    data/              # Scripts de coleta/processamento
    features/          # Scripts de feature engineering
    models/            # Scripts de modelagem
    visualization/     # Scripts de visualização
    utils/             # Utilitários gerais
 tests/                 # Testes automatizados
 docs/                  # Documentação
 results/               # Resultados e outputs
    figures/           # Gráficos e visualizações
    tables/            # Tabelas de resultados
    models/            # Modelos treinados
 references/            # Literatura e referências
\end{lstlisting}
\end{pythonbox}

\begin{researchbox}
\textbf{Caso Real - Projeto de Análise Longitudinal:}

Um pesquisador em psicologia estuda o desenvolvimento cognitivo em crianças ao longo de 5 anos:

\begin{lstlisting}[language=Python]
# src/data/longitudinal_processor.py
import pandas as pd
import numpy as np
from datetime import datetime
import logging

class LongitudinalDataProcessor:
    """Processador para dados longitudinais de desenvolvimento cognitivo"""
    
    def __init__(self, config):
        self.config = config
        self.logger = self._setup_logger()
        
    def _setup_logger(self):
        logging.basicConfig(
            filename=f'logs/processing_{datetime.now().strftime("%Y%m%d")}.log',
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)
    
    def load_raw_data(self, wave):
        """Carrega dados de uma onda específica do estudo"""
        try:
            filepath = f"data/raw/wave_{wave}_cognitive_tests.csv"
            data = pd.read_csv(filepath)
            self.logger.info(f"Carregados {len(data)} registros da onda {wave}")
            return data
        except FileNotFoundError:
            self.logger.error(f"Arquivo da onda {wave} não encontrado")
            raise
\end{lstlisting}
\end{researchbox}

\newpage

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Continuação: src/data/longitudinal_processor.py
    
    def validate_participant_ids(self, data, wave):
        """Valida consistência dos IDs de participantes"""
        expected_participants = self.config['participants_per_wave'][wave]
        actual_participants = len(data['participant_id'].unique())
        
        if actual_participants != expected_participants:
            self.logger.warning(
                f"Onda {wave}: esperados {expected_participants}, "
                f"encontrados {actual_participants} participantes"
            )
        
        return data
    
    def harmonize_test_scores(self, data):
        """Harmoniza escores de testes entre diferentes versões"""
        data['cognitive_score_std'] = data.groupby('age_group')['cognitive_score'].transform(
            lambda x: (x - x.mean()) / x.std()
        )
        return data
    
    def process_wave_data(self, wave):
        """Processa dados completos de uma onda"""
        # Carregar dados brutos
        data = self.load_raw_data(wave)
        
        # Validar participantes
        data = self.validate_participant_ids(data, wave)
        
        # Harmonizar escores
        data = self.harmonize_test_scores(data)
        
        # Salvar dados processados
        output_path = f"data/processed/wave_{wave}_processed.csv"
        data.to_csv(output_path, index=False)
        
        self.logger.info(f"Processamento da onda {wave} concluído")
        return data
\end{lstlisting}
\end{pythonbox}

\subsection{Configuração e Parametrização}

\begin{pythonbox}
\begin{lstlisting}
# config/research_config.yaml
project:
  name: "Desenvolvimento Cognitivo Longitudinal"
  version: "1.0.0"
  start_date: "2019-01-15"
  
data:
  waves: [1, 2, 3, 4, 5]
  participants_per_wave:
    1: 450
    2: 425
    3: 410
    4: 395
    5: 380
  
analysis:
  significance_level: 0.05
  minimum_effect_size: 0.3
  bootstrap_samples: 1000
  
models:
  growth_curve:
    method: "hierarchical_linear"
    random_effects: ["intercept", "slope"]
  
output:
  figures_dpi: 300
  table_format: "latex"
  decimal_places: 3
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# src/config/config_loader.py
import yaml
from pathlib import Path

def load_config(config_path="config/research_config.yaml"):
    """Carrega configurações do projeto"""
    with open(config_path, 'r', encoding='utf-8') as file:
        config = yaml.safe_load(file)
    return config

def validate_config(config):
    """Valida configurações obrigatórias"""
    required_keys = ['project', 'data', 'analysis']
    for key in required_keys:
        if key not in config:
            raise ValueError(f"Configuração '{key}' obrigatória não encontrada")
    return True

def get_analysis_params(config):
    """Extrai parâmetros para análise"""
    return {
        'alpha': config['analysis']['significance_level'],
        'min_effect_size': config['analysis']['minimum_effect_size'],
        'bootstrap_n': config['analysis']['bootstrap_samples']
    }

# Exemplo de uso
config = load_config()
validate_config(config)
analysis_params = get_analysis_params(config)
\end{lstlisting}
\end{pythonbox}

\section{Reprodutibilidade e Documentação}

A reprodutibilidade é um pilar fundamental da pesquisa científica. Python oferece diversas ferramentas para garantir que análises possam ser replicadas por outros pesquisadores ou pelo próprio autor em momentos futuros.

\subsection{Controle de Versões para Pesquisa}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# src/utils/reproducibility.py
import random
import numpy as np
import pandas as pd
import torch
from datetime import datetime
import hashlib
import os

class ReproducibilityManager:
    """Gerencia reprodutibilidade de experimentos"""
    
    def __init__(self, seed=42):
        self.seed = seed
        self.experiment_log = []
        
    def set_seeds(self):
        """Define seeds para todos os geradores de números aleatórios"""
        random.seed(self.seed)
        np.random.seed(self.seed)
        torch.manual_seed(self.seed)
        torch.cuda.manual_seed_all(self.seed)
        os.environ['PYTHONHASHSEED'] = str(self.seed)
        
        # Para reprodutibilidade completa no PyTorch
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
        
    def log_experiment(self, experiment_name, parameters):
        """Registra parâmetros de um experimento"""
        experiment_record = {
            'timestamp': datetime.now().isoformat(),
            'experiment': experiment_name,
            'seed': self.seed,
            'parameters': parameters,
            'hash': self._calculate_hash(parameters)
        }
        self.experiment_log.append(experiment_record)
\end{lstlisting}
\end{pythonbox}

\newpage

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Continuação: src/utils/reproducibility.py
        
    def _calculate_hash(self, parameters):
        """Calcula hash dos parâmetros para identificação única"""
        param_str = str(sorted(parameters.items()))
        return hashlib.md5(param_str.encode()).hexdigest()[:8]
    
    def save_experiment_log(self, filepath="results/experiment_log.json"):
        """Salva log de experimentos"""
        import json
        with open(filepath, 'w') as f:
            json.dump(self.experiment_log, f, indent=2)

# Exemplo de uso
repro = ReproducibilityManager(seed=42)
repro.set_seeds()

# Log do experimento
experiment_params = {
    'model_type': 'random_forest',
    'n_estimators': 100,
    'max_depth': 10,
    'feature_selection': 'mutual_info'
}
repro.log_experiment('cognitive_prediction_v1', experiment_params)
\end{lstlisting}
\end{pythonbox}

\section{Conclusão do Capítulo}

A metodologia de pesquisa com Python vai muito além do simples uso de bibliotecas para análise de dados. Ela engloba uma abordagem sistemática para estruturar projetos, garantir reprodutibilidade, facilitar colaboração e manter a qualidade científica ao longo de todo o ciclo de vida da pesquisa.

Os elementos fundamentais desta metodologia incluem:

\textbf{Estruturação e Planejamento:} Uma organização clara de diretórios e arquivos facilita não apenas o desenvolvimento atual, mas também a manutenção futura e a colaboração com outros pesquisadores.

\textbf{Reprodutibilidade como Prioridade:} O uso de seeds, controle de versões, documentação automatizada e ambientes virtuais garante que resultados possam ser replicados e verificados.

\textbf{Automação Inteligente:} Pipelines automatizados e sistemas de monitoramento reduzem erros humanos e aumentam a eficiência, especialmente em estudos longitudinais ou com múltiplas condições experimentais.

\textbf{Colaboração Efetiva:} Metodologias para projetos multi-site e ferramentas de harmonização de dados permitem que pesquisadores trabalhem juntos de forma produtiva, mesmo com diferenças culturais e técnicas.

\textbf{Qualidade Assegurada:} Testes automatizados e validação contínua identificam problemas precocemente, mantendo a integridade dos dados e análises.

No próximo capítulo, aplicaremos esses princípios metodológicos ao explorar técnicas avançadas de coleta e aquisição de dados, construindo sobre esta base sólida de boas práticas para desenvolver competências técnicas específicas na obtenção de dados de múltiplas fontes.

\begin{examplebox}
\textbf{Principais Aprendizados do Capítulo:}
\begin{itemize}
    \item Estruturação profissional de projetos de pesquisa
    \item Implementação de reprodutibilidade completa
    \item Uso efetivo de Git para pesquisa colaborativa
    \item Gestão robusta de ambientes e dependências
    \item Criação de pipelines automatizados de análise
    \item Desenvolvimento de testes para código científico
    \item Metodologias para projetos multi-institucionais
\end{itemize}
\end{examplebox}

A metodologia apresentada neste capítulo forma a espinha dorsal de qualquer projeto de pesquisa moderno com Python. Dominar esses conceitos não apenas melhora a qualidade técnica do trabalho, mas também facilita a colaboração, acelera descobertas e garante que os resultados possam contribuir efetivamente para o avanço do conhecimento científico.