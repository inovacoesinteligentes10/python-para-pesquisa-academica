% =============================================================================
% CAPÍTULO 8: MACHINE LEARNING PARA PESQUISADORES
% =============================================================================

\chapter{Machine Learning para Pesquisadores}

\lettrine{O}{machine learning} revolucionou a forma como pesquisadores abordam problemas complexos em diversas disciplinas acadêmicas. Desde a predição de resultados em experimentos até a descoberta de padrões ocultos em grandes datasets, as técnicas de aprendizado de máquina oferecem ferramentas poderosas para automatizar análises, fazer predições e extrair insights que seriam impossíveis de obter através de métodos tradicionais. Python, com seu ecossistema robusto de bibliotecas como scikit-learn, TensorFlow e PyTorch, democratizou o acesso a essas técnicas avançadas.

\section{Fundamentos do Machine Learning em Pesquisa}

Antes de implementar algoritmos complexos, é essencial compreender os fundamentos teóricos e práticos do machine learning aplicado à pesquisa acadêmica.

\subsection{Tipos de Problemas e Algoritmos}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# src/ml/ml_framework.py
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

class ResearchMLFramework:
    """Framework para aplicação de ML em pesquisa acadêmica"""
    
    def __init__(self, random_state: int = 42):
        self.random_state = random_state
        self.models = {}
        self.results = {}
        self.preprocessors = {}
        
    def identify_problem_type(self, target: pd.Series) -> str:
        """Identifica automaticamente o tipo de problema ML"""
        # Verificar se é variável categórica
        if target.dtype == 'object' or target.nunique() < 10:
            unique_values = target.nunique()
            if unique_values == 2:
                return 'binary_classification'
            elif unique_values <= 10:
                return 'multiclass_classification'
            else:
                return 'regression'
        
        # Verificar se é contínua
        elif np.issubdtype(target.dtype, np.number):
            # Se muitos valores únicos, provavelmente regressão
            if target.nunique() > target.count() * 0.1:
                return 'regression'
            else:
                return 'multiclass_classification'
        
        return 'regression'  # fallback
    
    def recommend_algorithms(self, problem_type: str, 
                           dataset_size: int) -> List[str]:
        """Recomenda algoritmos baseado no tipo de problema"""
        recommendations = {
            'binary_classification': {
                'small': ['logistic_regression', 'svm', 'naive_bayes'],
                'medium': ['random_forest', 'gradient_boosting', 'svm'],
                'large': ['logistic_regression', 'gradient_boosting', 'neural_network']
            },
            'multiclass_classification': {
                'small': ['random_forest', 'svm', 'knn'],
                'medium': ['random_forest', 'gradient_boosting', 'svm'],
                'large': ['gradient_boosting', 'neural_network', 'random_forest']
            },
            'regression': {
                'small': ['linear_regression', 'random_forest', 'svm'],
                'medium': ['random_forest', 'gradient_boosting', 'svm'],
                'large': ['gradient_boosting', 'neural_network', 'linear_regression']
            }
        }
        
        # Classificar tamanho do dataset
        if dataset_size < 1000:
            size_category = 'small'
        elif dataset_size < 10000:
            size_category = 'medium'
        else:
            size_category = 'large'
            
        return recommendations.get(problem_type, {}).get(size_category, ['random_forest'])
\end{lstlisting>
\end{pythonbox>

\newpage

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Continuação: src/ml/ml_framework.py
    
    def prepare_data(self, df: pd.DataFrame, 
                    target_column: str,
                    test_size: float = 0.2) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
        """Prepara dados para machine learning"""
        
        # Separar features e target
        X = df.drop(columns=[target_column])
        y = df[target_column]
        
        # Tratar valores faltantes
        X = self._handle_missing_values(X)
        
        # Codificar variáveis categóricas
        X = self._encode_categorical_variables(X)
        
        # Dividir em treino e teste
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state,
            stratify=y if self.identify_problem_type(y) != 'regression' else None
        )
        
        # Escalar features numéricas
        X_train, X_test = self._scale_features(X_train, X_test)
        
        return X_train, X_test, y_train, y_test
    
    def _handle_missing_values(self, X: pd.DataFrame) -> pd.DataFrame:
        """Trata valores faltantes"""
        X_processed = X.copy()
        
        for column in X_processed.columns:
            if X_processed[column].isnull().any():
                if X_processed[column].dtype == 'object':
                    # Variáveis categóricas: usar moda
                    mode_value = X_processed[column].mode()[0] if len(X_processed[column].mode()) > 0 else 'Unknown'
                    X_processed[column].fillna(mode_value, inplace=True)
                else:
                    # Variáveis numéricas: usar mediana
                    median_value = X_processed[column].median()
                    X_processed[column].fillna(median_value, inplace=True)
        
        return X_processed
    
    def _encode_categorical_variables(self, X: pd.DataFrame) -> pd.DataFrame:
        """Codifica variáveis categóricas"""
        X_processed = X.copy()
        
        for column in X_processed.columns:
            if X_processed[column].dtype == 'object':
                # Para variáveis com muitas categorias, usar target encoding
                if X_processed[column].nunique() > 10:
                    # Por simplicidade, usar label encoding
                    le = LabelEncoder()
                    X_processed[column] = le.fit_transform(X_processed[column].astype(str))
                    self.preprocessors[f'{column}_encoder'] = le
                else:
                    # Para poucas categorias, usar one-hot encoding
                    dummies = pd.get_dummies(X_processed[column], prefix=column)
                    X_processed = pd.concat([X_processed.drop(column, axis=1), dummies], axis=1)
        
        return X_processed
    
    def _scale_features(self, X_train: pd.DataFrame, 
                       X_test: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """Escala features numéricas"""
        scaler = StandardScaler()
        
        # Identificar colunas numéricas
        numeric_columns = X_train.select_dtypes(include=[np.number]).columns
        
        if len(numeric_columns) > 0:
            X_train_scaled = X_train.copy()
            X_test_scaled = X_test.copy()
            
            X_train_scaled[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])
            X_test_scaled[numeric_columns] = scaler.transform(X_test[numeric_columns])
            
            self.preprocessors['scaler'] = scaler
            
            return X_train_scaled, X_test_scaled
        
        return X_train, X_test
\end{lstlisting}
\end{pythonbox}

\begin{researchbox}
\textbf{Caso Real - Predição de Sucesso Acadêmico:}

Uma pesquisadora em educação quer prever o sucesso acadêmico de estudantes baseado em variáveis socioeconômicas e de desempenho:

\begin{lstlisting}[language=Python]
# src/ml/academic_success_predictor.py
from ml_framework import ResearchMLFramework
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

class AcademicSuccessPredictor:
    """Preditor de sucesso acadêmico usando ML"""
    
    def __init__(self):
        self.ml_framework = ResearchMLFramework()
        self.models = {}
        
    def load_and_analyze_data(self, filepath: str) -> pd.DataFrame:
        """Carrega e analisa dados acadêmicos"""
        df = pd.read_csv(filepath)
        
        # Análise exploratória básica
        print("Análise Exploratória dos Dados:")
        print(f"Dimensões: {df.shape}")
        print(f"Valores faltantes: {df.isnull().sum().sum()}")
        print(f"Variáveis categóricas: {df.select_dtypes(include=['object']).columns.tolist()}")
        
        return df
    
    def create_success_variable(self, df: pd.DataFrame) -> pd.DataFrame:
        """Cria variável binária de sucesso acadêmico"""
        # Assumindo que temos uma coluna 'nota_final'
        df_processed = df.copy()
        
        # Definir sucesso como nota >= 7.0
        df_processed['sucesso_academico'] = (df_processed['nota_final'] >= 7.0).astype(int)
        
        return df_processed
    
    def train_models(self, df: pd.DataFrame) -> Dict:
        """Treina múltiplos modelos para comparação"""
        # Preparar dados
        X_train, X_test, y_train, y_test = self.ml_framework.prepare_data(
            df, 'sucesso_academico'
        )
        
        # Modelos a serem testados
        models_to_test = {
            'logistic_regression': LogisticRegression(random_state=42),
            'random_forest': RandomForestClassifier(random_state=42, n_estimators=100)
        }
        
        results = {}
        
        for name, model in models_to_test.items():
            # Treinar modelo
            model.fit(X_train, y_train)
            
            # Fazer predições
            y_pred = model.predict(X_test)
            
            # Avaliar performance
            report = classification_report(y_test, y_pred, output_dict=True)
            
            results[name] = {
                'model': model,
                'predictions': y_pred,
                'classification_report': report,
                'accuracy': report['accuracy']
            }
            
            print(f"\nResultados - {name}:")
            print(f"Acurácia: {report['accuracy']:.3f}")
            print(f"F1-Score: {report['macro avg']['f1-score']:.3f}")
        
        self.models = results
        return results
\end{lstlisting}
\end{researchbox}

\section{Classificação para Problemas de Pesquisa}

A classificação é uma das tarefas mais comuns em machine learning aplicado à pesquisa, permitindo categorizar observações em grupos predefinidos.

\subsection{Classificação Binária e Multiclasse}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# src/ml/classification_toolkit.py
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.model_selection import cross_val_score, GridSearchCV
import matplotlib.pyplot as plt

class ClassificationToolkit:
    """Toolkit para problemas de classificação em pesquisa"""
    
    def __init__(self, random_state: int = 42):
        self.random_state = random_state
        self.models = self._initialize_models()
        self.best_model = None
        self.best_params = None
        
    def _initialize_models(self) -> Dict:
        """Inicializa modelos de classificação"""
        return {
            'logistic_regression': LogisticRegression(random_state=self.random_state),
            'random_forest': RandomForestClassifier(random_state=self.random_state),
            'gradient_boosting': GradientBoostingClassifier(random_state=self.random_state),
            'svm': SVC(random_state=self.random_state),
            'naive_bayes': GaussianNB()
        }
    
    def compare_algorithms(self, X_train: pd.DataFrame, 
                          y_train: pd.Series,
                          cv_folds: int = 5) -> pd.DataFrame:
        """Compara performance de diferentes algoritmos"""
        results = []
        
        for name, model in self.models.items():
            try:
                # Validação cruzada
                cv_scores = cross_val_score(
                    model, X_train, y_train, 
                    cv=cv_folds, scoring='accuracy'
                )


\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]                
                results.append({
                    'algorithm': name,
                    'mean_accuracy': cv_scores.mean(),
                    'std_accuracy': cv_scores.std(),
                    'min_accuracy': cv_scores.min(),
                    'max_accuracy': cv_scores.max()
                })
                
            except Exception as e:
                print(f"Erro ao treinar {name}: {e}")
                continue
        
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values('mean_accuracy', ascending=False)
        
        return results_df
    
    def hyperparameter_tuning(self, X_train: pd.DataFrame, 
                             y_train: pd.Series,
                             algorithm: str = 'random_forest') -> Dict:
        """Otimização de hiperparâmetros"""
        param_grids = {
            'random_forest': {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20],
                'min_samples_split': [2, 5, 10]
            },
            'logistic_regression': {
                'C': [0.1, 1.0, 10.0],
                'penalty': ['l1', 'l2'],
                'solver': ['liblinear']
            },
            'svm': {
                'C': [0.1, 1.0, 10.0],
                'kernel': ['rbf', 'linear'],
                'gamma': ['scale', 'auto']
            }
        }
        
        if algorithm not in param_grids:
            raise ValueError(f"Algoritmo {algorithm} não suportado")
        
        model = self.models[algorithm]
        param_grid = param_grids[algorithm]

\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]          
        # Grid search com validação cruzada

        
        grid_search = GridSearchCV(
            model, param_grid, cv=5, 
            scoring='accuracy', n_jobs=-1
        )
        
        grid_search.fit(X_train, y_train)
        
        self.best_model = grid_search.best_estimator_
        self.best_params = grid_search.best_params_
        
        return {
            'best_params': grid_search.best_params_,
            'best_score': grid_search.best_score_,
            'best_model': grid_search.best_estimator_
        }
\end{lstlisting}
\end{pythonbox}

\newpage

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Continuação: src/ml/classification_toolkit.py
    
    def evaluate_model(self, model, X_test: pd.DataFrame, 
                      y_test: pd.Series) -> Dict:
        """Avalia performance detalhada do modelo"""
        y_pred = model.predict(X_test)
        
        # Métricas básicas
        accuracy = accuracy_score(y_test, y_pred)
        precision, recall, f1, support = precision_recall_fscore_support(
            y_test, y_pred, average='weighted'
        )
        
        # Métricas por classe
        precision_per_class, recall_per_class, f1_per_class, _ = \
            precision_recall_fscore_support(y_test, y_pred, average=None)
        
        # Matriz de confusão
        from sklearn.metrics import confusion_matrix
        cm = confusion_matrix(y_test, y_pred)
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'precision_per_class': precision_per_class,
            'recall_per_class': recall_per_class,
            'f1_per_class': f1_per_class,
            'confusion_matrix': cm,
            'predictions': y_pred
        }
    
    def feature_importance_analysis(self, model, 
                                   feature_names: List[str]) -> pd.DataFrame:
        """Analisa importância das features"""
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
        elif hasattr(model, 'coef_'):
            # Para modelos lineares, usar valor absoluto dos coeficientes
            importances = np.abs(model.coef_[0] if len(model.coef_.shape) > 1 else model.coef_)
        else:
            print("Modelo não suporta análise de importância")
            return pd.DataFrame()
\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]          
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        return importance_df
    
    def plot_performance_comparison(self, results_df: pd.DataFrame):
        """Visualiza comparação de performance"""
        plt.figure(figsize=(12, 6))
        
        # Gráfico de barras com erro
        plt.errorbar(
            range(len(results_df)), 
            results_df['mean_accuracy'],
            yerr=results_df['std_accuracy'],
            fmt='o', capsize=5, capthick=2
        )
        
        plt.bar(range(len(results_df)), results_df['mean_accuracy'], 
                alpha=0.7, color='skyblue')
        
        plt.xlabel('Algoritmos')
        plt.ylabel('Acurácia Média')
        plt.title('Comparação de Performance entre Algoritmos')
        plt.xticks(range(len(results_df)), results_df['algorithm'], rotation=45)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()

# Exemplo de uso
toolkit = ClassificationToolkit()

# Dados exemplo (substituir por dados reais)
X_train = pd.DataFrame(np.random.randn(1000, 5), 
                      columns=['feature1', 'feature2', 'feature3', 'feature4', 'feature5'])
y_train = pd.Series(np.random.choice([0, 1], 1000))

# Comparar algoritmos
comparison_results = toolkit.compare_algorithms(X_train, y_train)
print("Comparação de Algoritmos:")
print(comparison_results)

# Otimizar melhor algoritmo
best_algorithm = comparison_results.iloc[0]['algorithm']
tuning_results = toolkit.hyperparameter_tuning(X_train, y_train, best_algorithm)
print(f"\nMelhores parâmetros para {best_algorithm}:")
print(tuning_results['best_params'])
\end{lstlisting}
\end{pythonbox}

\section{Regressão para Predição Quantitativa}

A regressão permite prever valores contínuos, essencial para estudos que envolvem medições quantitativas e análises preditivas.

\subsection{Regressão Linear e Não-Linear}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# src/ml/regression_toolkit.py
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt

class RegressionToolkit:
    """Toolkit para problemas de regressão em pesquisa"""
    
    def __init__(self, random_state: int = 42):
        self.random_state = random_state
        self.models = self._initialize_models()
        self.trained_models = {}
        
    def _initialize_models(self) -> Dict:
        """Inicializa modelos de regressão"""
        return {
            'linear_regression': LinearRegression(),
            'ridge_regression': Ridge(random_state=self.random_state),
            'lasso_regression': Lasso(random_state=self.random_state),
            'elastic_net': ElasticNet(random_state=self.random_state),
            'random_forest': RandomForestRegressor(random_state=self.random_state),
            'gradient_boosting': GradientBoostingRegressor(random_state=self.random_state),
            'svr': SVR()
        }
    
    def compare_regression_models(self, X_train: pd.DataFrame, 
                                 y_train: pd.Series) -> pd.DataFrame:
        """Compara diferentes modelos de regressão"""
        results = []
        
        for name, model in self.models.items():
            try:
                # Validação cruzada para R2
                r2_scores = cross_val_score(
                    model, X_train, y_train, 
                    cv=5, scoring='r2'
                )
\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]                  
                # Validação cruzada para MSE (negativo)
                mse_scores = -cross_val_score(
                    model, X_train, y_train, 
                    cv=5, scoring='neg_mean_squared_error'
                )
                
                results.append({
                    'algorithm': name,
                    'mean_r2': r2_scores.mean(),
                    'std_r2': r2_scores.std(),
                    'mean_mse': mse_scores.mean(),
                    'std_mse': mse_scores.std(),
                    'mean_rmse': np.sqrt(mse_scores.mean())
                })
                
                # Treinar modelo para análises posteriores
                model.fit(X_train, y_train)
                self.trained_models[name] = model
                
            except Exception as e:
                print(f"Erro ao treinar {name}: {e}")
                continue
        
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values('mean_r2', ascending=False)
        
        return results_df
    
    def detailed_evaluation(self, model, X_test: pd.DataFrame, 
                           y_test: pd.Series, model_name: str) -> Dict:
        """Avaliação detalhada de modelo de regressão"""
        y_pred = model.predict(X_test)
        
        # Métricas
        r2 = r2_score(y_test, y_pred)
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        
        # Erro percentual absoluto médio
        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
        
        return {
            'model_name': model_name,
            'r2_score': r2,
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'mape': mape,
            'predictions': y_pred,
            'residuals': y_test - y_pred
        }
\end{lstlisting}
\end{pythonbox}

\newpage

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Continuação: src/ml/regression_toolkit.py
    
    def plot_regression_diagnostics(self, evaluation_results: Dict):
        """Cria gráficos de diagnóstico para regressão"""
        y_true = evaluation_results['predictions'] + evaluation_results['residuals']
        y_pred = evaluation_results['predictions']
        residuals = evaluation_results['residuals']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. Valores preditos vs valores reais
        axes[0,0].scatter(y_true, y_pred, alpha=0.6)
        axes[0,0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
        axes[0,0].set_xlabel('Valores Reais')
        axes[0,0].set_ylabel('Valores Preditos')
        axes[0,0].set_title('Predições vs Valores Reais')
        
        # 2. Resíduos vs valores preditos
        axes[0,1].scatter(y_pred, residuals, alpha=0.6)
        axes[0,1].axhline(y=0, color='r', linestyle='--')
        axes[0,1].set_xlabel('Valores Preditos')
        axes[0,1].set_ylabel('Resíduos')
        axes[0,1].set_title('Resíduos vs Valores Preditos')
        
        # 3. Histograma dos resíduos
        axes[1,0].hist(residuals, bins=30, alpha=0.7, color='skyblue')
        axes[1,0].set_xlabel('Resíduos')
        axes[1,0].set_ylabel('Frequência')
        axes[1,0].set_title('Distribuição dos Resíduos')
        
        # 4. Q-Q plot dos resíduos
        from scipy import stats
        stats.probplot(residuals, dist="norm", plot=axes[1,1])
        axes[1,1].set_title('Q-Q Plot dos Resíduos')
        
        plt.tight_layout()
        plt.show()
        
        # Estatísticas dos resíduos
        print(f"Estatísticas dos Resíduos:")
        print(f"Média: {residuals.mean():.4f}")
        print(f"Desvio Padrão: {residuals.std():.4f}")
        print(f"Teste de Normalidade (Shapiro-Wilk): {stats.shapiro(residuals)[1]:.4f}")
    \end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]  
    def feature_importance_regression(self, model, 
                                    feature_names: List[str]) -> pd.DataFrame:
        """Analisa importância das features em regressão"""
        if hasattr(model, 'feature_importances_'):
            # Modelos baseados em árvores
            importances = model.feature_importances_
        elif hasattr(model, 'coef_'):
            # Modelos lineares
            importances = np.abs(model.coef_)
        else:
            print("Modelo não suporta análise de importância")
            return pd.DataFrame()
        
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        return importance_df

# Exemplo de uso
regression_toolkit = RegressionToolkit()

# Dados exemplo (substituir por dados reais)
X_train = pd.DataFrame(np.random.randn(1000, 5), 
                      columns=['var1', 'var2', 'var3', 'var4', 'var5'])
y_train = pd.Series(2*X_train['var1'] + X_train['var2'] + np.random.randn(1000)*0.5)

# Comparar modelos de regressão
regression_comparison = regression_toolkit.compare_regression_models(X_train, y_train)
print("Comparação de Modelos de Regressão:")
print(regression_comparison[['algorithm', 'mean_r2', 'mean_rmse']])

# Avaliar melhor modelo
best_model_name = regression_comparison.iloc[0]['algorithm']
best_model = regression_toolkit.trained_models[best_model_name]

# Criar dados de teste
X_test = pd.DataFrame(np.random.randn(200, 5), 
                     columns=['var1', 'var2', 'var3', 'var4', 'var5'])
y_test = pd.Series(2*X_test['var1'] + X_test['var2'] + np.random.randn(200)*0.5)

# Avaliação detalhada
evaluation = regression_toolkit.detailed_evaluation(best_model, X_test, y_test, best_model_name)
print(f"\nAvaliação do {best_model_name}:")
print(f"R2 Score: {evaluation['r2_score']:.4f}")
print(f"RMSE: {evaluation['rmse']:.4f}")
print(f"MAE: {evaluation['mae']:.4f}")
\end{lstlisting}
\end{pythonbox}

\section{Aprendizado Não Supervisionado}

O aprendizado não supervisionado permite descobrir padrões ocultos em dados sem variáveis target predefinidas, essencial para análise exploratória e descoberta de insights.

\subsection{Clustering e Análise de Componentes}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# src/ml/unsupervised_toolkit.py
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.decomposition import PCA, FactorAnalysis
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, adjusted_rand_score
import matplotlib.pyplot as plt
import seaborn as sns

class UnsupervisedToolkit:
    """Toolkit para aprendizado não supervisionado em pesquisa"""
    
    def __init__(self, random_state: int = 42):
        self.random_state = random_state
        self.clustering_models = {}
        self.dimensionality_models = {}
        
    def optimal_clusters_analysis(self, X: pd.DataFrame, 
                                 max_clusters: int = 10) -> Dict:
        """Determina número ótimo de clusters usando múltiplos métodos"""
        X_scaled = StandardScaler().fit_transform(X)
        
        # Método do cotovelo (inércia)
        inertias = []
        silhouette_scores = []
        k_range = range(2, max_clusters + 1)
        
        for k in k_range:
            kmeans = KMeans(n_clusters=k, random_state=self.random_state, n_init=10)
            cluster_labels = kmeans.fit_predict(X_scaled)
            
            inertias.append(kmeans.inertia_)
            silhouette_scores.append(silhouette_score(X_scaled, cluster_labels))
        
        # Encontrar cotovelo
        optimal_k_elbow = self._find_elbow_point(k_range, inertias)
        optimal_k_silhouette = k_range[np.argmax(silhouette_scores)]
        
        return {
            'k_range': list(k_range),
            'inertias': inertias,
            'silhouette_scores': silhouette_scores,
            'optimal_k_elbow': optimal_k_elbow,
            'optimal_k_silhouette': optimal_k_silhouette,
            'max_silhouette_score': max(silhouette_scores)
        }
    \end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]  
    def _find_elbow_point(self, k_range: range, inertias: List[float]) -> int:
        """Encontra o ponto do cotovelo na curva de inércia"""
        # Método da segunda derivada
        if len(inertias) < 3:
            return k_range[0]
            
        # Calcular diferenças
        first_diff = np.diff(inertias)
        second_diff = np.diff(first_diff)
        
        # Encontrar ponto onde a segunda derivada é máxima
        elbow_idx = np.argmax(second_diff) + 2  # +2 devido aos diffs
        return list(k_range)[min(elbow_idx, len(k_range) - 1)]
    
    def apply_clustering_algorithms(self, X: pd.DataFrame, 
                                   n_clusters: int = 3) -> Dict:
        """Aplica diferentes algoritmos de clustering"""
        X_scaled = StandardScaler().fit_transform(X)
        
        algorithms = {
            'kmeans': KMeans(n_clusters=n_clusters, random_state=self.random_state),
            'agglomerative': AgglomerativeClustering(n_clusters=n_clusters),
            'dbscan': DBSCAN(eps=0.5, min_samples=5)
        }
        
        results = {}
        
        for name, algorithm in algorithms.items():
            cluster_labels = algorithm.fit_predict(X_scaled)
            
            # Calcular métricas (se houver mais de 1 cluster)
            if len(np.unique(cluster_labels)) > 1:
                silhouette = silhouette_score(X_scaled, cluster_labels)
            else:
                silhouette = -1
            
            results[name] = {
                'labels': cluster_labels,
                'n_clusters_found': len(np.unique(cluster_labels)),
                'silhouette_score': silhouette,
                'model': algorithm
            }
            
            self.clustering_models[name] = algorithm
        
        return results
\end{lstlisting}
\end{pythonbox}

\newpage

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Continuação: src/ml/unsupervised_toolkit.py
    
    def dimensionality_reduction(self, X: pd.DataFrame, 
                                n_components: int = 2) -> Dict:
        """Aplica técnicas de redução de dimensionalidade"""
        X_scaled = StandardScaler().fit_transform(X)
        
        # PCA
        pca = PCA(n_components=n_components, random_state=self.random_state)
        X_pca = pca.fit_transform(X_scaled)
        
        # t-SNE
        tsne = TSNE(n_components=n_components, random_state=self.random_state)
        X_tsne = tsne.fit_transform(X_scaled)
        
        # Factor Analysis
        fa = FactorAnalysis(n_components=n_components, random_state=self.random_state)
        X_fa = fa.fit_transform(X_scaled)
        
        results = {
            'pca': {
                'transformed_data': X_pca,
                'explained_variance_ratio': pca.explained_variance_ratio_,
                'cumulative_variance': np.cumsum(pca.explained_variance_ratio_),
                'model': pca
            },
            'tsne': {
                'transformed_data': X_tsne,
                'model': tsne
            },
            'factor_analysis': {
                'transformed_data': X_fa,
                'model': fa
            }
        }
        
        self.dimensionality_models = {
            'pca': pca,
            'tsne': tsne,
            'factor_analysis': fa
        }
        
        return results
\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]      
    def plot_clustering_results(self, X: pd.DataFrame, 
                               clustering_results: Dict,
                               reduction_results: Dict):
        """Visualiza resultados de clustering"""
        n_algorithms = len(clustering_results)
        fig, axes = plt.subplots(1, n_algorithms, figsize=(5*n_algorithms, 4))
        
        if n_algorithms == 1:
            axes = [axes]
        
        # Usar PCA para visualização 2D
        X_pca = reduction_results['pca']['transformed_data']
        
        for i, (name, result) in enumerate(clustering_results.items()):
            labels = result['labels']
            n_clusters = result['n_clusters_found']
            silhouette = result['silhouette_score']
            
            scatter = axes[i].scatter(X_pca[:, 0], X_pca[:, 1], 
                                    c=labels, cmap='viridis', alpha=0.6)
            axes[i].set_title(f'{name.title()}\n'
                            f'Clusters: {n_clusters}, Silhouette: {silhouette:.3f}')
            axes[i].set_xlabel('PC1')
            axes[i].set_ylabel('PC2')
            
            # Adicionar colorbar
            plt.colorbar(scatter, ax=axes[i])
        
        plt.tight_layout()
        plt.show()
    
    def analyze_cluster_characteristics(self, X: pd.DataFrame, 
                                      cluster_labels: np.ndarray) -> pd.DataFrame:
        """Analisa características de cada cluster"""
        df_with_clusters = X.copy()
        df_with_clusters['cluster'] = cluster_labels
        
        # Estatísticas por cluster
        cluster_stats = df_with_clusters.groupby('cluster').agg([
            'mean', 'std', 'median', 'count'
        ]).round(3)
        
        return cluster_stats
\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]  
# Exemplo de uso
unsupervised_toolkit = UnsupervisedToolkit()

# Dados exemplo
np.random.seed(42)
X_example = pd.DataFrame({
    'feature1': np.concatenate([np.random.normal(0, 1, 100), np.random.normal(3, 1, 100)]),
    'feature2': np.concatenate([np.random.normal(0, 1, 100), np.random.normal(3, 1, 100)]),
    'feature3': np.concatenate([np.random.normal(1, 0.5, 100), np.random.normal(2, 0.5, 100)])
})

# Análise do número ótimo de clusters
optimal_analysis = unsupervised_toolkit.optimal_clusters_analysis(X_example)
print(f"Número ótimo de clusters (cotovelo): {optimal_analysis['optimal_k_elbow']}")
print(f"Número ótimo de clusters (silhouette): {optimal_analysis['optimal_k_silhouette']}")

# Aplicar algoritmos de clustering
clustering_results = unsupervised_toolkit.apply_clustering_algorithms(X_example, n_clusters=2)

# Redução de dimensionalidade
reduction_results = unsupervised_toolkit.dimensionality_reduction(X_example)

print(f"Variância explicada pelo PCA: {reduction_results['pca']['explained_variance_ratio']}")
\end{lstlisting}
\end{pythonbox}

\section{Validação e Interpretação de Modelos}

A validação rigorosa e interpretação adequada dos modelos são fundamentais para garantir a confiabilidade dos resultados em pesquisa acadêmica.

\subsection{Técnicas de Validação Cruzada}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# src/ml/model_validation.py
import pandas as pd
import numpy as np
from sklearn.model_selection import (
    cross_val_score, StratifiedKFold, TimeSeriesSplit,
    validation_curve, learning_curve
)
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple

class ModelValidation:
    """Classe para validação rigorosa de modelos ML"""
    
    def __init__(self, random_state: int = 42):
        self.random_state = random_state
        
    def comprehensive_cross_validation(self, model, X: pd.DataFrame, 
                                     y: pd.Series, 
                                     problem_type: str = 'classification') -> Dict:
        """Validação cruzada abrangente"""
        results = {}
        
        # Escolher estratégia de validação
        if problem_type == 'classification':
            cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, 
                                        random_state=self.random_state)
            scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']
        else:  # regression
            cv_strategy = 5  # KFold padrão
            scoring_metrics = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']
        
        # Calcular métricas
        for metric in scoring_metrics:
            scores = cross_val_score(model, X, y, cv=cv_strategy, scoring=metric)
            results[metric] = {
                'scores': scores,
                'mean': scores.mean(),
                'std': scores.std(),
                'ci_95': (scores.mean() - 1.96*scores.std(), 
                         scores.mean() + 1.96*scores.std())
            }
        
        return results
\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]      
    def temporal_validation(self, model, X: pd.DataFrame, 
                           y: pd.Series, n_splits: int = 5) -> Dict:
        """Validação para dados temporais"""
        tscv = TimeSeriesSplit(n_splits=n_splits)
        
        fold_results = []
        for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            
            # Treinar e avaliar
            model.fit(X_train, y_train)
            score = model.score(X_test, y_test)
            
            fold_results.append({
                'fold': fold,
                'train_size': len(train_idx),
                'test_size': len(test_idx),
                'score': score
            })
        
        return {
            'fold_results': fold_results,
            'mean_score': np.mean([r['score'] for r in fold_results]),
            'std_score': np.std([r['score'] for r in fold_results])
        }
    
    def learning_curve_analysis(self, model, X: pd.DataFrame, 
                               y: pd.Series) -> Dict:
        """Análise de curva de aprendizado"""
        train_sizes = np.linspace(0.1, 1.0, 10)
        
        train_sizes_abs, train_scores, val_scores = learning_curve(
            model, X, y, train_sizes=train_sizes, cv=5,
            random_state=self.random_state, n_jobs=-1
        )
        
        return {
            'train_sizes': train_sizes_abs,
            'train_scores_mean': train_scores.mean(axis=1),
            'train_scores_std': train_scores.std(axis=1),
            'val_scores_mean': val_scores.mean(axis=1),
            'val_scores_std': val_scores.std(axis=1)
        }
\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]      
    def plot_learning_curves(self, learning_results: Dict, 
                            title: str = "Curvas de Aprendizado"):
        """Visualiza curvas de aprendizado"""
        plt.figure(figsize=(10, 6))
        
        train_sizes = learning_results['train_sizes']
        train_mean = learning_results['train_scores_mean']
        train_std = learning_results['train_scores_std']
        val_mean = learning_results['val_scores_mean']
        val_std = learning_results['val_scores_std']
        
        # Curvas de treino
        plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Score de Treino')
        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, 
                        alpha=0.2, color='blue')
        
        # Curvas de validação
        plt.plot(train_sizes, val_mean, 'o-', color='red', label='Score de Validação')
        plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, 
                        alpha=0.2, color='red')
        
        plt.xlabel('Tamanho do Conjunto de Treino')
        plt.ylabel('Score')
        plt.title(title)
        plt.legend(loc='best')
        plt.grid(True, alpha=0.3)
        plt.show()
\end{lstlisting}
\end{pythonbox}

\newpage

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Continuação: src/ml/model_validation.py
    
    def statistical_significance_test(self, model1_scores: np.ndarray,
                                    model2_scores: np.ndarray,
                                    alpha: float = 0.05) -> Dict:
        """Teste de significância estatística entre modelos"""
        from scipy import stats
        
        # Teste t pareado
        t_stat, p_value = stats.ttest_rel(model1_scores, model2_scores)
        
        # Teste de Wilcoxon (não-paramétrico)
        wilcoxon_stat, wilcoxon_p = stats.wilcoxon(model1_scores, model2_scores)
        
        return {
            't_statistic': t_stat,
            't_test_p_value': p_value,
            't_test_significant': p_value < alpha,
            'wilcoxon_statistic': wilcoxon_stat,
            'wilcoxon_p_value': wilcoxon_p,
            'wilcoxon_significant': wilcoxon_p < alpha,
            'mean_difference': np.mean(model1_scores - model2_scores)
        }
    
    def bootstrap_confidence_interval(self, model, X: pd.DataFrame, 
                                    y: pd.Series, 
                                    n_bootstrap: int = 1000,
                                    confidence: float = 0.95) -> Dict:

\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]                                      
        """Calcula intervalo de confiança via bootstrap"""
        bootstrap_scores = []
        
        for _ in range(n_bootstrap):
            # Amostragem com reposição
            indices = np.random.choice(len(X), size=len(X), replace=True)
            X_boot = X.iloc[indices]
            y_boot = y.iloc[indices]
            
            # Dividir em treino e teste
            split_idx = int(0.8 * len(X_boot))
            X_train, X_test = X_boot[:split_idx], X_boot[split_idx:]
            y_train, y_test = y_boot[:split_idx], y_boot[split_idx:]
            
            # Treinar e avaliar
            model.fit(X_train, y_train)
            score = model.score(X_test, y_test)
            bootstrap_scores.append(score)
        
        bootstrap_scores = np.array(bootstrap_scores)
        
        # Calcular intervalo de confiança
        alpha = 1 - confidence
        lower_percentile = (alpha/2) * 100
        upper_percentile = (1 - alpha/2) * 100
        
        ci_lower = np.percentile(bootstrap_scores, lower_percentile)
        ci_upper = np.percentile(bootstrap_scores, upper_percentile)
        
        return {
            'bootstrap_scores': bootstrap_scores,
            'mean_score': bootstrap_scores.mean(),
            'std_score': bootstrap_scores.std(),
            'confidence_interval': (ci_lower, ci_upper),
            'confidence_level': confidence
        }

# Exemplo de uso
validator = ModelValidation()

# Dados exemplo
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier

X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)
X_df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])
y_series = pd.Series(y)

model = RandomForestClassifier(random_state=42)
\end{lstlisting}
\end{pythonbox}
\begin{pythonbox}
\begin{lstlisting}[language=Python]  
# Validação cruzada abrangente
cv_results = validator.comprehensive_cross_validation(model, X_df, y_series)
print("Resultados da Validação Cruzada:")
for metric, results in cv_results.items():
    print(f"{metric}: {results['mean']:.3f} +/- {results['std']:.3f}")

# Análise de curva de aprendizado
learning_results = validator.learning_curve_analysis(model, X_df, y_series)
validator.plot_learning_curves(learning_results)

# Bootstrap confidence interval
bootstrap_results = validator.bootstrap_confidence_interval(model, X_df, y_series)
print(f"\nIntervalo de Confiança (Bootstrap):")
print(f"Score médio: {bootstrap_results['mean_score']:.3f}")
print(f"95% CI: {bootstrap_results['confidence_interval']}")
\end{lstlisting}
\end{pythonbox}

\section{Conclusão do Capítulo}

O machine learning transformou fundamentalmente a paisagem da pesquisa acadêmica, oferecendo ferramentas poderosas para análise de dados complexos, predição de resultados e descoberta de padrões ocultos. Python, através de seu ecossistema robusto de bibliotecas, democratizou o acesso a essas técnicas avançadas.

Os elementos fundamentais abordados neste capítulo incluem:

\textbf{Framework Metodológico:} Estrutura sistemática para identificação de problemas, seleção de algoritmos e preparação de dados adaptada às necessidades da pesquisa acadêmica.

\textbf{Técnicas de Classificação:} Métodos supervisionados para categorização de observações, essenciais para estudos em ciências sociais, medicina e psicologia.

\textbf{Modelos de Regressão:} Abordagens para predição quantitativa, fundamentais para análises econômicas, físicas e experimentais.

\textbf{Aprendizado Não Supervisionado:} Técnicas para descoberta de padrões em dados sem rótulos, cruciais para análise exploratória e segmentação.

\textbf{Validação Rigorosa:} Métodos estatisticamente sólidos para avaliação de modelos, garantindo confiabilidade e reprodutibilidade dos resultados.

\begin{examplebox}
\textbf{Principais Competências Desenvolvidas:}
\begin{itemize}
    \item Identificação automática de tipos de problemas ML
    \item Implementação de pipelines completos de machine learning
    \item Comparação sistemática de algoritmos
    \item Otimização de hiperparâmetros
    \item Técnicas de clustering e redução de dimensionalidade
    \item Validação estatisticamente rigorosa de modelos
    \item Interpretação e comunicação de resultados
\end{itemize}
\end{examplebox}

As técnicas apresentadas neste capítulo capacitam pesquisadores a extrair insights sophisticados de dados complexos, automatizar processos de análise e fazer predições confiáveis. O machine learning não substitui o rigor científico tradicional, mas o amplifica, permitindo análises em escalas e complexidades antes inimagináveis.

No próximo capítulo, exploraremos técnicas avançadas de visualização de dados, construindo sobre os fundamentos de análise para criar representações visuais que comuniquem efetivamente os insights descobertos através das técnicas de machine learning e análise estatística apresentadas até aqui.