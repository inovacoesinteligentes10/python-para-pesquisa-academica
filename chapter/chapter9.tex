% =============================================================================
% CAPÍTULO 9: ANÁLISE DE SÉRIES TEMPORAIS
% =============================================================================

\chapter{Análise de Séries Temporais}

\lettrine{A}{análise de séries temporais} é fundamental para compreender fenômenos que evoluem ao longo do tempo. Na pesquisa acadêmica, encontramos dados temporais em diversas áreas: desde variações climáticas até indicadores econômicos, de padrões de comportamento animal até dados epidemiológicos. Python oferece ferramentas poderosas para extrair insights significativos desses dados temporais.

\section{Dados Temporais em Pesquisa}

\subsection{Características dos Dados Temporais}

Os dados de séries temporais possuem características únicas que os distinguem de outros tipos de dados. A dependência temporal significa que observações próximas no tempo tendem a ser correlacionadas, violando a suposição de independência de muitos métodos estatísticos tradicionais.

\begin{pythonbox}
\begin{lstlisting}[language=Python]
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Configuração para gráficos
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Criando dados simulados de temperatura para pesquisa climática
np.random.seed(42)
datas = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')

# Simulando temperatura com tendência, sazonalidade e ruído
tendencia = np.linspace(15, 17, len(datas))  # Aquecimento gradual
sazonalidade = 10 * np.sin(2 * np.pi * np.arange(len(datas)) / 365.25)
ruido = np.random.normal(0, 2, len(datas))

temperatura = tendencia + sazonalidade + ruido
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Criando DataFrame
df_clima = pd.DataFrame({
    'data': datas,
    'temperatura': temperatura
})

print("Estrutura dos dados temporais:")
print(df_clima.head())
print(f"Período: {df_clima['data'].min()} a {df_clima['data'].max()}")
print(f"Número de observações: {len(df_clima)}")
\end{lstlisting}
\end{pythonbox}

\subsection{Importação e Preparação de Dados Temporais}

\begin{examplebox}
Vamos trabalhar com dados reais de pesquisa acadêmica. Considere um estudo sobre padrões de atividade acadêmica em publicações científicas:
\end{examplebox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Simulando dados de um estudo sobre produtividade acadêmica
np.random.seed(123)

# Dados de publicações científicas por mês
datas_pub = pd.date_range(start='2015-01-01', end='2023-12-31', freq='M')

# Simulando padrões realistas de publicação
base_pub = 50
crescimento = np.linspace(0, 30, len(datas_pub))
sazon_acad = 15 * np.sin(2 * np.pi * np.arange(len(datas_pub)) / 12 + np.pi/2)
eventos_esp = np.zeros(len(datas_pub))
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Simulando impacto da pandemia (2020-2021)
pandemia_inicio = ((datas_pub >= '2020-03-01') & 
                   (datas_pub <= '2020-12-31'))
pandemia_recup = ((datas_pub >= '2021-01-01') & 
                  (datas_pub <= '2021-12-31'))

eventos_esp[pandemia_inicio] = -20
eventos_esp[pandemia_recup] = 10

ruido = np.random.normal(0, 8, len(datas_pub))
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
publicacoes = (base_pub + crescimento + sazon_acad + 
               eventos_esp + ruido).astype(int)
publicacoes = np.maximum(publicacoes, 10)  # Mínimo de 10 publicações

# Criando DataFrame principal
df_academico = pd.DataFrame({
    'data': datas_pub,
    'publicacoes': publicacoes,
    'ano': datas_pub.year,
    'mes': datas_pub.month,
    'trimestre': datas_pub.quarter
})

# Configurando índice temporal
df_academico.set_index('data', inplace=True)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
print("Dataset de produtividade acadêmica:")
print(df_academico.head(10))
print(f"\nEstatísticas descritivas:")
print(df_academico['publicacoes'].describe())
\end{lstlisting}
\end{pythonbox}

\subsection{Visualização Inicial dos Dados}

A visualização é o primeiro passo para compreender uma série temporal. Devemos observar tendências, padrões sazonais, outliers e possíveis quebras estruturais.

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Criando visualizações exploratórias
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Gráfico principal da série
axes[0, 0].plot(df_academico.index, df_academico['publicacoes'], 
                linewidth=1.5, color='steelblue')
axes[0, 0].set_title('Série Temporal: Publicações Científicas por Mês', 
                     fontsize=12, fontweight='bold')
axes[0, 0].set_ylabel('Número de Publicações')
axes[0, 0].grid(True, alpha=0.3)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Destacando período da pandemia
pandemia_mask = ((df_academico.index >= '2020-03-01') & 
                 (df_academico.index <= '2021-12-31'))
axes[0, 0].fill_between(df_academico.index[pandemia_mask], 
                        df_academico['publicacoes'][pandemia_mask],
                        alpha=0.3, color='red', label='Período Pandemia')
axes[0, 0].legend()

# Padrão sazonal por mês
publicacoes_por_mes = df_academico.groupby('mes')['publicacoes'].mean()
axes[0, 1].bar(range(1, 13), publicacoes_por_mes.values, 
               color='lightcoral', alpha=0.7)
axes[0, 1].set_title('Padrão Sazonal Médio por Mês', 
                     fontsize=12, fontweight='bold')
axes[0, 1].set_xlabel('Mês')
axes[0, 1].set_ylabel('Publicações Médias')
axes[0, 1].set_xticks(range(1, 13))
axes[0, 1].grid(True, alpha=0.3)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Tendência anual
publicacoes_por_ano = df_academico.groupby('ano')['publicacoes'].sum()
axes[1, 0].plot(publicacoes_por_ano.index, publicacoes_por_ano.values, 
                marker='o', linewidth=2, markersize=6, color='darkgreen')
axes[1, 0].set_title('Tendência Anual: Total de Publicações', 
                     fontsize=12, fontweight='bold')
axes[1, 0].set_xlabel('Ano')
axes[1, 0].set_ylabel('Total de Publicações')
axes[1, 0].grid(True, alpha=0.3)

# Distribuição dos valores
axes[1, 1].hist(df_academico['publicacoes'], bins=20, 
                color='orange', alpha=0.7, edgecolor='black')
axes[1, 1].set_title('Distribuição dos Valores', 
                     fontsize=12, fontweight='bold')
axes[1, 1].set_xlabel('Número de Publicações')
axes[1, 1].set_ylabel('Frequência')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\section{Decomposição e Tendências}

\subsection{Decomposição de Séries Temporais}

A decomposição permite separar uma série temporal em seus componentes fundamentais: tendência, sazonalidade e ruído. Isso facilita a compreensão dos padrões subjacentes.

\begin{pythonbox}
\begin{lstlisting}[language=Python]
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# Decomposição da série temporal
decomposicao = seasonal_decompose(df_academico['publicacoes'], 
                                  model='additive', period=12)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Visualizando a decomposição
fig, axes = plt.subplots(4, 1, figsize=(15, 12))

# Série original
axes[0].plot(df_academico.index, df_academico['publicacoes'], 
             color='black', linewidth=1.5)
axes[0].set_title('Série Original', fontsize=12, fontweight='bold')
axes[0].set_ylabel('Publicações')
axes[0].grid(True, alpha=0.3)

# Tendência
axes[1].plot(df_academico.index, decomposicao.trend, 
             color='red', linewidth=2)
axes[1].set_title('Componente de Tendência', fontsize=12, fontweight='bold')
axes[1].set_ylabel('Tendência')
axes[1].grid(True, alpha=0.3)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Sazonalidade
axes[2].plot(df_academico.index, decomposicao.seasonal, 
             color='blue', linewidth=1.5)
axes[2].set_title('Componente Sazonal', fontsize=12, fontweight='bold')
axes[2].set_ylabel('Sazonalidade')
axes[2].grid(True, alpha=0.3)

# Resíduo
axes[3].plot(df_academico.index, decomposicao.resid, 
             color='green', linewidth=1)
axes[3].set_title('Resíduo (Ruído)', fontsize=12, fontweight='bold')
axes[3].set_ylabel('Resíduo')
axes[3].set_xlabel('Data')
axes[3].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Análise dos componentes
print("Análise da Decomposição:")
print(f"Variabilidade da tendência: {decomposicao.trend.std():.2f}")
print(f"Variabilidade sazonal: {decomposicao.seasonal.std():.2f}")
print(f"Variabilidade do ruído: {decomposicao.resid.std():.2f}")
\end{lstlisting}
\end{pythonbox}

\subsection{Detecção de Mudanças Estruturais}

\begin{researchbox}
Em pesquisa acadêmica, é crucial identificar quando ocorrem mudanças significativas nos padrões dos dados. Por exemplo, o impacto de políticas públicas ou eventos externos como a pandemia.
\end{researchbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
from scipy import stats
import ruptures as rpt

# Detecção de pontos de mudança usando Ruptures
# Preparando os dados
serie_valores = df_academico['publicacoes'].values

# Detectando mudanças na média usando Pelt
modelo = rpt.Pelt(model="rbf").fit(serie_valores)
pontos_mudanca = modelo.predict(pen=10)

# Removendo o último ponto (que é sempre o final da série)
pontos_mudanca = pontos_mudanca[:-1]
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Convertendo índices para datas
datas_mudanca = [df_academico.index[i] for i in pontos_mudanca]

print("Pontos de mudança detectados:")
for i, data in enumerate(datas_mudanca):
    print(f"Mudança {i+1}: {data.strftime('%Y-%m')}")
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Visualizando os pontos de mudança
plt.figure(figsize=(15, 6))
plt.plot(df_academico.index, df_academico['publicacoes'], 
         linewidth=1.5, color='steelblue', label='Série Original')

# Marcando os pontos de mudança
for data in datas_mudanca:
    plt.axvline(x=data, color='red', linestyle='--', alpha=0.8)

plt.title('Detecção de Mudanças Estruturais na Série', 
          fontsize=14, fontweight='bold')
plt.xlabel('Data')
plt.ylabel('Número de Publicações')
plt.legend()
plt.grid(True, alpha=0.3)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Análise estatística dos períodos
print("\nAnálise estatística por período:")
pontos_completos = [0] + pontos_mudanca + [len(df_academico)]

for i in range(len(pontos_completos)-1):
    inicio = pontos_completos[i]
    fim = pontos_completos[i+1]
    periodo_dados = df_academico.iloc[inicio:fim]['publicacoes']
    
    data_inicio = df_academico.index[inicio].strftime('%Y-%m')
    data_fim = df_academico.index[fim-1].strftime('%Y-%m')
    
    print(f"Período {i+1} ({data_inicio} a {data_fim}):")
    print(f"  Média: {periodo_dados.mean():.2f}")
    print(f"  Desvio padrão: {periodo_dados.std():.2f}")
    print(f"  Mediana: {periodo_dados.median():.2f}")
    print()
\end{lstlisting}
\end{pythonbox}

\section{Modelos ARIMA e Previsão}

\subsection{Fundamentos dos Modelos ARIMA}

Os modelos ARIMA (AutoRegressive Integrated Moving Average) são fundamentais para análise e previsão de séries temporais. Eles combinam três componentes: autorregressão (AR), diferenciação (I) e média móvel (MA).

\begin{pythonbox}
\begin{lstlisting}[language=Python]
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_absolute_error, mean_squared_error
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Teste de estacionariedade (Teste de Dickey-Fuller Aumentado)
def teste_estacionariedade(serie, titulo='Série'):
    """Realiza teste de estacionariedade e exibe resultados"""
    resultado = adfuller(serie.dropna())
    
    print(f'Teste de Estacionariedade - {titulo}:')
    print(f'Estatística ADF: {resultado[0]:.6f}')
    print(f'p-valor: {resultado[1]:.6f}')
    print(f'Valores críticos:')
    for chave, valor in resultado[4].items():
        print(f'\t{chave}: {valor:.3f}')
    
    if resultado[1] <= 0.05:
        print("Resultado: A série é estacionária (rejeita H0)")
    else:
        print("Resultado: A série não é estacionária (não rejeita H0)")
    print('-' * 50)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Testando estacionariedade da série original
teste_estacionariedade(df_academico['publicacoes'], 'Original')

# Aplicando diferenciação se necessário
df_academico['pub_diff1'] = df_academico['publicacoes'].diff()
teste_estacionariedade(df_academico['pub_diff1'], 'Primeira Diferença')
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Visualizando ACF e PACF para identificar parâmetros ARIMA
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Série original
axes[0, 0].plot(df_academico.index, df_academico['publicacoes'])
axes[0, 0].set_title('Série Original')
axes[0, 0].grid(True, alpha=0.3)

# Série diferenciada
axes[0, 1].plot(df_academico.index, df_academico['pub_diff1'])
axes[0, 1].set_title('Primeira Diferença')
axes[0, 1].grid(True, alpha=0.3)

# ACF da série diferenciada
plot_acf(df_academico['pub_diff1'].dropna(), ax=axes[1, 0], lags=24)
axes[1, 0].set_title('Função de Autocorrelação (ACF)')

# PACF da série diferenciada
plot_pacf(df_academico['pub_diff1'].dropna(), ax=axes[1, 1], lags=24)
axes[1, 1].set_title('Função de Autocorrelação Parcial (PACF)')

plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\subsection{Seleção e Ajuste do Modelo ARIMA}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
from itertools import product

# Função para seleção automática de parâmetros ARIMA
def selecionar_arima(serie, max_p=3, max_d=2, max_q=3):
    """
    Seleciona os melhores parâmetros ARIMA usando AIC
    """
    melhor_aic = np.inf
    melhor_params = None
    melhor_modelo = None
    
    # Testando diferentes combinações de parâmetros
    for p in range(max_p + 1):
        for d in range(max_d + 1):
            for q in range(max_q + 1):
                try:
                    modelo = ARIMA(serie, order=(p, d, q))
                    resultado = modelo.fit()
                    
                    if resultado.aic < melhor_aic:
                        melhor_aic = resultado.aic
                        melhor_params = (p, d, q)
                        melhor_modelo = resultado
                        
                except:
                    continue
    
    return melhor_params, melhor_modelo, melhor_aic
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Dividindo os dados em treino e teste (80%-20%)
tamanho_treino = int(len(df_academico) * 0.8)
treino = df_academico['publicacoes'][:tamanho_treino]
teste = df_academico['publicacoes'][tamanho_treino:]

print(f"Período de treino: {treino.index[0]} a {treino.index[-1]}")
print(f"Período de teste: {teste.index[0]} a {teste.index[-1]}")

# Selecionando o melhor modelo
melhor_params, modelo_ajustado, melhor_aic = selecionar_arima(treino)

print(f"\nMelhor modelo ARIMA{melhor_params}")
print(f"AIC: {melhor_aic:.2f}")
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
print("\nResumo do modelo:")
print(modelo_ajustado.summary())
\end{lstlisting}
\end{pythonbox}

\subsection{Previsão e Validação}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Fazendo previsões
previsoes = modelo_ajustado.forecast(steps=len(teste))
intervalo_confianca = modelo_ajustado.get_forecast(steps=len(teste))
ic = intervalo_confianca.conf_int()

# Calculando métricas de erro
mae = mean_absolute_error(teste, previsoes)
rmse = np.sqrt(mean_squared_error(teste, previsoes))
mape = np.mean(np.abs((teste - previsoes) / teste)) * 100

print(f"Métricas de Avaliação:")
print(f"MAE (Erro Absoluto Médio): {mae:.2f}")
print(f"RMSE (Raiz do Erro Quadrático Médio): {rmse:.2f}")
print(f"MAPE (Erro Percentual Absoluto Médio): {mape:.2f}%")
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Visualizando previsões
plt.figure(figsize=(15, 8))

# Dados de treino
plt.plot(treino.index, treino.values, label='Dados de Treino', 
         color='blue', linewidth=1.5)

# Dados de teste (valores reais)
plt.plot(teste.index, teste.values, label='Valores Reais', 
         color='green', linewidth=2)

# Previsões
plt.plot(teste.index, previsoes, label='Previsões ARIMA', 
         color='red', linewidth=2, linestyle='--')

# Intervalo de confiança
plt.fill_between(teste.index, ic.iloc[:, 0], ic.iloc[:, 1], 
                 color='red', alpha=0.2, label='IC 95%')
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
plt.title(f'Previsão ARIMA{melhor_params} - Publicações Científicas', 
          fontsize=14, fontweight='bold')
plt.xlabel('Data')
plt.ylabel('Número de Publicações')
plt.legend()
plt.grid(True, alpha=0.3)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Análise dos resíduos
residuos = modelo_ajustado.resid

fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Resíduos ao longo do tempo
axes[0, 0].plot(residuos.index, residuos.values)
axes[0, 0].set_title('Resíduos ao Longo do Tempo')
axes[0, 0].set_ylabel('Resíduos')
axes[0, 0].grid(True, alpha=0.3)

# Histograma dos resíduos
axes[0, 1].hist(residuos.dropna(), bins=20, alpha=0.7, color='orange')
axes[0, 1].set_title('Distribuição dos Resíduos')
axes[0, 1].set_xlabel('Resíduos')
axes[0, 1].set_ylabel('Frequência')
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Q-Q plot
from scipy import stats
stats.probplot(residuos.dropna(), dist="norm", plot=axes[1, 0])
axes[1, 0].set_title('Q-Q Plot dos Resíduos')

# ACF dos resíduos
plot_acf(residuos.dropna(), ax=axes[1, 1], lags=20)
axes[1, 1].set_title('ACF dos Resíduos')

plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\section{Análise de Sazonalidade}

\subsection{Identificação de Padrões Sazonais}

A sazonalidade é um componente crucial em muitas séries temporais acadêmicas. Vamos explorar métodos para identificar e modelar esses padrões.

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Análise sazonal detalhada
from statsmodels.tsa.seasonal import STL

# Decomposição STL (Seasonal and Trend decomposition using Loess)
stl = STL(df_academico['publicacoes'], seasonal=13)  # seasonal=13 para dados mensais
resultado_stl = stl.fit()

# Visualizando decomposição STL
fig = resultado_stl.plot()
fig.suptitle('Decomposição STL - Publicações Científicas', 
             fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Análise de sazonalidade por diferentes períodos
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Padrão mensal
monthly_pattern = df_academico.groupby(df_academico.index.month)['publicacoes'].agg(['mean', 'std'])
axes[0, 0].bar(monthly_pattern.index, monthly_pattern['mean'], 
               yerr=monthly_pattern['std'], capsize=5, alpha=0.7, color='skyblue')
axes[0, 0].set_title('Padrão Sazonal Mensal')
axes[0, 0].set_xlabel('Mês')
axes[0, 0].set_ylabel('Publicações Médias')
axes[0, 0].set_xticks(range(1, 13))
axes[0, 0].grid(True, alpha=0.3)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Padrão trimestral
quarterly_pattern = df_academico.groupby('trimestre')['publicacoes'].agg(['mean', 'std'])
axes[0, 1].bar(quarterly_pattern.index, quarterly_pattern['mean'], 
               yerr=quarterly_pattern['std'], capsize=5, alpha=0.7, color='lightgreen')
axes[0, 1].set_title('Padrão Sazonal Trimestral')
axes[0, 1].set_xlabel('Trimestre')
axes[0, 1].set_ylabel('Publicações Médias')
axes[0, 1].grid(True, alpha=0.3)

# Heatmap sazonal
pivot_sazonal = df_academico.pivot_table(values='publicacoes', 
                                         index=df_academico.index.year, 
                                         columns=df_academico.index.month, 
                                         aggfunc='mean')

sns.heatmap(pivot_sazonal, annot=True, fmt='.0f', cmap='YlOrRd', 
            ax=axes[1, 0], cbar_kws={'label': 'Publicações'})
axes[1, 0].set_title('Heatmap Sazonal (Ano x Mês)')
axes[1, 0].set_xlabel('Mês')
axes[1, 0].set_ylabel('Ano')
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Boxplot por mês
df_academico.boxplot(column='publicacoes', by=df_academico.index.month, 
                     ax=axes[1, 1])
axes[1, 1].set_title('Distribuição por Mês')
axes[1, 1].set_xlabel('Mês')
axes[1, 1].set_ylabel('Publicações')

plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Teste estatístico de sazonalidade
from scipy.stats import kruskal

# Teste de Kruskal-Wallis para sazonalidade mensal
grupos_mensais = [df_academico[df_academico.index.month == m]['publicacoes'].values 
                  for m in range(1, 13)]
stat_kruskal, p_valor = kruskal(*grupos_mensais)

print(f"Teste de Kruskal-Wallis para Sazonalidade Mensal:")
print(f"Estatística: {stat_kruskal:.4f}")
print(f"p-valor: {p_valor:.6f}")

if p_valor < 0.05:
    print("Resultado: Há evidência significativa de sazonalidade mensal")
else:
    print("Resultado: Não há evidência significativa de sazonalidade mensal")
\end{lstlisting}
\end{pythonbox}

\subsection{Modelagem Sazonal com SARIMA}

\begin{researchbox}
Para séries com sazonalidade clara, os modelos SARIMA (Seasonal ARIMA) são mais apropriados, pois incluem componentes sazonais explícitos.
\end{researchbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Função para seleção de parâmetros SARIMA
def selecionar_sarima(serie, max_p=2, max_d=1, max_q=2, 
                     max_P=1, max_D=1, max_Q=1, s=12):
    """
    Seleciona os melhores parâmetros SARIMA usando AIC
    """
    melhor_aic = np.inf
    melhor_params = None
    melhor_modelo = None
    
    for p in range(max_p + 1):
        for d in range(max_d + 1):
            for q in range(max_q + 1):
                for P in range(max_P + 1):
                    for D in range(max_D + 1):
                        for Q in range(max_Q + 1):
                            try:
                                modelo = SARIMAX(serie, 
                                                order=(p, d, q),
                                                seasonal_order=(P, D, Q, s))
                                resultado = modelo.fit(disp=False)
                                
                                if resultado.aic < melhor_aic:
                                    melhor_aic = resultado.aic
                                    melhor_params = ((p, d, q), (P, D, Q, s))
                                    melhor_modelo = resultado
                                    
                            except:
                                continue
    
    return melhor_params, melhor_modelo, melhor_aic
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Selecionando o melhor modelo SARIMA
print("Selecionando modelo SARIMA... (pode demorar alguns minutos)")
melhor_params_sarima, modelo_sarima, melhor_aic_sarima = selecionar_sarima(treino)

print(f"\nMelhor modelo SARIMA{melhor_params_sarima[0]}x{melhor_params_sarima[1]}")
print(f"AIC: {melhor_aic_sarima:.2f}")

# Fazendo previsões com SARIMA
previsoes_sarima = modelo_sarima.forecast(steps=len(teste))
ic_sarima = modelo_sarima.get_forecast(steps=len(teste)).conf_int()
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Métricas de avaliação SARIMA
mae_sarima = mean_absolute_error(teste, previsoes_sarima)
rmse_sarima = np.sqrt(mean_squared_error(teste, previsoes_sarima))
mape_sarima = np.mean(np.abs((teste - previsoes_sarima) / teste)) * 100

print(f"\nMétricas SARIMA:")
print(f"MAE: {mae_sarima:.2f}")
print(f"RMSE: {rmse_sarima:.2f}")
print(f"MAPE: {mape_sarima:.2f}%")

print(f"\nComparação com ARIMA:")
print(f"ARIMA - MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%")
print(f"SARIMA - MAE: {mae_sarima:.2f}, RMSE: {rmse_sarima:.2f}, MAPE: {mape_sarima:.2f}%")
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Visualizando comparação entre modelos
plt.figure(figsize=(15, 8))

# Dados históricos
plt.plot(treino.index, treino.values, label='Dados de Treino', 
         color='blue', linewidth=1.5)
plt.plot(teste.index, teste.values, label='Valores Reais', 
         color='green', linewidth=2)

# Previsões ARIMA
plt.plot(teste.index, previsoes, label=f'ARIMA{melhor_params}', 
         color='red', linewidth=2, linestyle='--', alpha=0.8)

# Previsões SARIMA
plt.plot(teste.index, previsoes_sarima, 
         label=f'SARIMA{melhor_params_sarima[0]}x{melhor_params_sarima[1]}', 
         color='purple', linewidth=2, linestyle=':', alpha=0.8)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Intervalo de confiança SARIMA
plt.fill_between(teste.index, ic_sarima.iloc[:, 0], ic_sarima.iloc[:, 1], 
                 color='purple', alpha=0.2, label='IC 95% SARIMA')

plt.title('Comparação: ARIMA vs SARIMA - Publicações Científicas', 
          fontsize=14, fontweight='bold')
plt.xlabel('Data')
plt.ylabel('Número de Publicações')
plt.legend()
plt.grid(True, alpha=0.3)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\subsection{Análise de Ciclos Acadêmicos}

\begin{examplebox}
Na pesquisa acadêmica, é importante compreender os ciclos específicos da área. Por exemplo, períodos de submissão de artigos, calendário de conferências, e ciclos de financiamento.
\end{examplebox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Análise de ciclos específicos da área acadêmica
from scipy.fft import fft, fftfreq
from scipy.signal import find_peaks

# Análise espectral para identificar periodicidades
def analise_espectral(serie, freq_amostragem=12):
    """
    Realiza análise espectral para identificar periodicidades dominantes
    """
    # Removendo tendência (detrending)
    serie_detrend = serie - np.polyval(np.polyfit(range(len(serie)), 
                                                  serie, 1), range(len(serie)))
    
    # Transformada de Fourier
    fft_valores = fft(serie_detrend)
    frequencias = fftfreq(len(serie_detrend), 1/freq_amostragem)
    
    # Magnitude do espectro (apenas frequências positivas)
    n = len(frequencias) // 2
    magnitude = np.abs(fft_valores[:n])
    freq_positivas = frequencias[:n]
    
    # Convertendo frequências para períodos
    periodos = 1 / freq_positivas[1:]  # Excluindo frequência zero
    magnitude = magnitude[1:]
    
    return periodos, magnitude
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Aplicando análise espectral
periodos, magnitude = analise_espectral(df_academico['publicacoes'].values)

# Identificando picos no espectro
picos, propriedades = find_peaks(magnitude, height=np.max(magnitude)*0.1)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Visualizando análise espectral
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Espectro de potência
axes[0, 0].plot(periodos, magnitude, linewidth=1.5, color='navy')
axes[0, 0].scatter(periodos[picos], magnitude[picos], 
                   color='red', s=50, zorder=5)
axes[0, 0].set_title('Espectro de Potência - Identificação de Ciclos')
axes[0, 0].set_xlabel('Período (meses)')
axes[0, 0].set_ylabel('Magnitude')
axes[0, 0].set_xlim(0, 24)
axes[0, 0].grid(True, alpha=0.3)

# Anotando os principais períodos detectados
for i, pico in enumerate(picos[:5]):  # Mostrando apenas os 5 principais
    periodo_detectado = periodos[pico]
    axes[0, 0].annotate(f'{periodo_detectado:.1f}m', 
                        xy=(periodo_detectado, magnitude[pico]),
                        xytext=(periodo_detectado, magnitude[pico] + magnitude[pico]*0.1),
                        ha='center', fontsize=9, color='red')
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Análise por semestre acadêmico (assumindo início em março e setembro)
df_academico['semestre'] = np.where(df_academico.index.month.isin([3,4,5,6,7,8]), 1, 2)
semestre_stats = df_academico.groupby(['ano', 'semestre'])['publicacoes'].agg(['mean', 'sum', 'std'])

# Visualizando padrões semestrais
sem1_values = semestre_stats[semestre_stats.index.get_level_values(1) == 1]['mean'].values
sem2_values = semestre_stats[semestre_stats.index.get_level_values(1) == 2]['mean'].values

anos = semestre_stats.index.get_level_values(0).unique()
x = np.arange(len(anos))

axes[0, 1].bar(x - 0.2, sem1_values, 0.4, label='1º Semestre', alpha=0.7, color='lightblue')
axes[0, 1].bar(x + 0.2, sem2_values, 0.4, label='2º Semestre', alpha=0.7, color='orange')
axes[0, 1].set_title('Publicações Médias por Semestre Acadêmico')
axes[0, 1].set_xlabel('Ano')
axes[0, 1].set_ylabel('Publicações Médias')
axes[0, 1].set_xticks(x)
axes[0, 1].set_xticklabels(anos, rotation=45)
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Análise de concentração de publicações por período do ano
trimestre_concentracao = df_academico.groupby(['ano', 'trimestre'])['publicacoes'].sum().unstack()
trimestre_pct = trimestre_concentracao.div(trimestre_concentracao.sum(axis=1), axis=0) * 100

# Heatmap de concentração por trimestre
im = axes[1, 0].imshow(trimestre_pct.values, cmap='YlOrRd', aspect='auto')
axes[1, 0].set_title('Concentração de Publicações por Trimestre (%)')
axes[1, 0].set_xlabel('Trimestre')
axes[1, 0].set_ylabel('Ano')
axes[1, 0].set_xticks(range(4))
axes[1, 0].set_xticklabels(['Q1', 'Q2', 'Q3', 'Q4'])
axes[1, 0].set_yticks(range(len(trimestre_pct.index)))
axes[1, 0].set_yticklabels(trimestre_pct.index)

# Adicionando colorbar
cbar = plt.colorbar(im, ax=axes[1, 0])
cbar.set_label('Concentração (%)')
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Padrão de crescimento anual
crescimento_anual = df_academico.groupby('ano')['publicacoes'].sum().pct_change() * 100
axes[1, 1].bar(crescimento_anual.index[1:], crescimento_anual.values[1:], 
               color=['red' if x < 0 else 'green' for x in crescimento_anual.values[1:]], 
               alpha=0.7)
axes[1, 1].axhline(y=0, color='black', linestyle='-', alpha=0.8)
axes[1, 1].set_title('Taxa de Crescimento Anual (%)')
axes[1, 1].set_xlabel('Ano')
axes[1, 1].set_ylabel('Crescimento (%)')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Relatório de análise de sazonalidade
print("=" * 60)
print("RELATÓRIO DE ANÁLISE DE SAZONALIDADE")
print("=" * 60)

print(f"\n1. PERÍODOS DOMINANTES DETECTADOS:")
for i, pico in enumerate(picos[:3]):
    periodo = periodos[pico]
    print(f"   Período {i+1}: {periodo:.1f} meses")

print(f"\n2. ANÁLISE SEMESTRAL:")
print(f"   Média 1º Semestre: {np.mean(sem1_values):.1f} publicações")
print(f"   Média 2º Semestre: {np.mean(sem2_values):.1f} publicações")
diferenca_rel = ((np.mean(sem2_values) - np.mean(sem1_values))/np.mean(sem1_values)*100)
print(f"   Diferença relativa: {diferenca_rel:.1f}%")

print(f"\n3. CONCENTRAÇÃO TRIMESTRAL MÉDIA:")
concentracao_media = trimestre_pct.mean()
for i, trimestre in enumerate(['Q1', 'Q2', 'Q3', 'Q4']):
    print(f"   {trimestre}: {concentracao_media.iloc[i]:.1f}%")

print(f"\n4. CRESCIMENTO MÉDIO ANUAL: {np.mean(crescimento_anual.dropna()):.1f}%")
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Teste de sazonalidade mais rigoroso
from statsmodels.stats.diagnostic import acorr_ljungbox

# Teste de Ljung-Box nos resíduos dessazonalizados
serie_dessazonalizada = df_academico['publicacoes'] - resultado_stl.seasonal
residuos_dessaz = serie_dessazonalizada - serie_dessazonalizada.rolling(12).mean()

ljung_box = acorr_ljungbox(residuos_dessaz.dropna(), lags=12, return_df=True)
print(f"\n5. TESTE DE LJUNG-BOX (Autocorrelação Residual):")
print(f"   p-valor mínimo: {ljung_box['lb_pvalue'].min():.6f}")

if ljung_box['lb_pvalue'].min() > 0.05:
    print("   Resultado: Não há autocorrelação significativa nos resíduos")
else:
    print("   Resultado: Ainda há autocorrelação nos resíduos")
\end{lstlisting}
\end{pythonbox}

\subsection{Previsão com Incerteza Sazonal}

\begin{warningbox}
Ao fazer previsões de séries sazonais, é crucial considerar que a incerteza aumenta em períodos tradicionalmente mais voláteis. Sempre forneça intervalos de confiança junto com as previsões pontuais.
\end{warningbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Previsão estendida com análise de incerteza sazonal
horizonte_previsao = 12  # 12 meses à frente

# Previsão com modelo SARIMA
previsao_futura = modelo_sarima.forecast(steps=horizonte_previsao)
ic_futuro = modelo_sarima.get_forecast(steps=horizonte_previsao).conf_int()

# Criando datas futuras
ultima_data = df_academico.index[-1]
datas_futuras = pd.date_range(start=ultima_data + pd.DateOffset(months=1), 
                              periods=horizonte_previsao, freq='M')
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Análise de incerteza por período sazonal
incerteza_sazonal = []
for i, data_futura in enumerate(datas_futuras):
    mes = data_futura.month
    
    # Histórico de variabilidade para o mesmo mês
    dados_mes = df_academico[df_academico.index.month == mes]['publicacoes']
    variabilidade_historica = dados_mes.std()
    
    # Incerteza da previsão
    ic_amplitude = ic_futuro.iloc[i, 1] - ic_futuro.iloc[i, 0]
    
    incerteza_sazonal.append({
        'mes': mes,
        'data': data_futura,
        'previsao': previsao_futura.iloc[i],
        'ic_inferior': ic_futuro.iloc[i, 0],
        'ic_superior': ic_futuro.iloc[i, 1],
        'variabilidade_historica': variabilidade_historica,
        'amplitude_ic': ic_amplitude
    })

df_incerteza = pd.DataFrame(incerteza_sazonal)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Visualizando previsões com análise de incerteza
fig, axes = plt.subplots(2, 1, figsize=(15, 12))

# Gráfico principal de previsão
ultimos_24_meses = df_academico.tail(24)
axes[0].plot(ultimos_24_meses.index, ultimos_24_meses['publicacoes'], 
             'o-', label='Dados Históricos', color='blue', linewidth=2)

axes[0].plot(datas_futuras, previsao_futura, 'o-', 
             label='Previsão SARIMA', color='red', linewidth=2)

axes[0].fill_between(datas_futuras, df_incerteza['ic_inferior'], 
                     df_incerteza['ic_superior'], 
                     alpha=0.3, color='red', label='IC 95%')
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Destacando períodos de maior incerteza
alta_incerteza = df_incerteza['amplitude_ic'] > df_incerteza['amplitude_ic'].median()
axes[0].scatter(df_incerteza[alta_incerteza]['data'], 
                df_incerteza[alta_incerteza]['previsao'],
                s=100, color='orange', marker='*', 
                label='Alta Incerteza', zorder=5)

axes[0].set_title('Previsão com Análise de Incerteza Sazonal', 
                  fontsize=14, fontweight='bold')
axes[0].set_ylabel('Número de Publicações')
axes[0].legend()
axes[0].grid(True, alpha=0.3)
axes[0].tick_params(axis='x', rotation=45)
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Gráfico de incerteza por mês
meses_nomes = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun',
               'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']

incerteza_por_mes = df_incerteza.groupby('mes')['amplitude_ic'].mean()
variabilidade_por_mes = df_incerteza.groupby('mes')['variabilidade_historica'].mean()

x = range(1, 13)
axes[1].bar([i-0.2 for i in x], [incerteza_por_mes.get(i, 0) for i in x], 
            0.4, label='Incerteza da Previsão', alpha=0.7, color='red')
axes[1].bar([i+0.2 for i in x], [variabilidade_por_mes.get(i, 0) for i in x], 
            0.4, label='Variabilidade Histórica', alpha=0.7, color='blue')

axes[1].set_title('Incerteza da Previsão vs Variabilidade Histórica por Mês')
axes[1].set_xlabel('Mês')
axes[1].set_ylabel('Amplitude da Incerteza')
axes[1].set_xticks(x)
axes[1].set_xticklabels(meses_nomes)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
# Relatório de previsão
print("=" * 70)
print("RELATÓRIO DE PREVISÃO - PRÓXIMOS 12 MESES")
print("=" * 70)

print(f"\nPREVISÃO MENSAL:")
for _, row in df_incerteza.iterrows():
    mes_nome = meses_nomes[row['mes']-1]
    print(f"{row['data'].strftime('%Y-%m')} ({mes_nome}): "
          f"{row['previsao']:.0f} publicações "
          f"[{row['ic_inferior']:.0f} - {row['ic_superior']:.0f}]")

print(f"\nRESUMO ESTATÍSTICO:")
print(f"Total previsto (12 meses): {df_incerteza['previsao'].sum():.0f} publicações")
print(f"Média mensal: {df_incerteza['previsao'].mean():.1f} publicações")

max_idx = df_incerteza['previsao'].idxmax()
min_idx = df_incerteza['previsao'].idxmin()
print(f"Mês com maior previsão: {meses_nomes[df_incerteza.loc[max_idx, 'mes']-1]} "
      f"({df_incerteza['previsao'].max():.0f} publicações)")
print(f"Mês com menor previsão: {meses_nomes[df_incerteza.loc[min_idx, 'mes']-1]} "
      f"({df_incerteza['previsao'].min():.0f} publicações)")
\end{lstlisting}
\end{pythonbox}

\begin{pythonbox}
\begin{lstlisting}[language=Python]
print(f"\nANÁLISE DE INCERTEZA:")
max_inc_idx = df_incerteza['amplitude_ic'].idxmax()
min_inc_idx = df_incerteza['amplitude_ic'].idxmin()
print(f"Período de maior incerteza: {meses_nomes[df_incerteza.loc[max_inc_idx, 'mes']-1]}")
print(f"Período de menor incerteza: {meses_nomes[df_incerteza.loc[min_inc_idx, 'mes']-1]}")
print(f"Incerteza média: ±{df_incerteza['amplitude_ic'].mean()/2:.1f} publicações")

# Comparação com tendência histórica
crescimento_historico = df_academico.tail(12)['publicacoes'].sum()
crescimento_previsto = df_incerteza['previsao'].sum()
variacao_percentual = ((crescimento_previsto - crescimento_historico) / crescimento_historico) * 100

print(f"\nCOMPARAÇÃO COM PERÍODO ANTERIOR:")
print(f"Últimos 12 meses: {crescimento_historico:.0f} publicações")
print(f"Próximos 12 meses (previsto): {crescimento_previsto:.0f} publicações")
print(f"Variação esperada: {variacao_percentual:+.1f}%")
\end{lstlisting}
\end{pythonbox}

\section{Considerações Finais do Capítulo}

A análise de séries temporais em contextos acadêmicos requer cuidado especial com as características específicas dos dados de pesquisa. Fatores como sazonalidade acadêmica, eventos externos (pandemias, mudanças de política), e ciclos de financiamento podem ter impactos significativos nas séries.

Os métodos apresentados neste capítulo fornecem uma base sólida para:

\begin{itemize}
\item Identificar e modelar padrões temporais em dados de pesquisa
\item Fazer previsões robustas considerando incertezas sazonais
\item Detectar mudanças estruturais em séries temporais
\item Avaliar o impacto de eventos externos nos dados
\end{itemize}

É importante lembrar que a qualidade das previsões depende fundamentalmente da qualidade e representatividade dos dados históricos. Sempre valide os modelos com dados externos e considere fatores qualitativos que podem não estar capturados nos dados quantitativos.

\begin{researchbox}
\textbf{Aplicações Práticas:} Os métodos deste capítulo podem ser aplicados em estudos longitudinais, análise de tendências de citações, previsão de demanda por recursos de pesquisa, monitoramento de indicadores acadêmicos, e avaliação de impacto de políticas científicas.
\end{researchbox}